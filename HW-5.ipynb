{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Fundamentals of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Generalization: The goal of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Noisy training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Ambiguous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rare features and spurious correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding white-noise channels or all-zeros channels to MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training the same model on MNIST data with noise channels or all-zero channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 4s 3ms/step - loss: 0.6243 - accuracy: 0.8100 - val_loss: 0.2890 - val_accuracy: 0.9133\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9211 - val_loss: 0.1784 - val_accuracy: 0.9495\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1634 - accuracy: 0.9501 - val_loss: 0.1376 - val_accuracy: 0.9597\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1161 - accuracy: 0.9638 - val_loss: 0.1610 - val_accuracy: 0.9543\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.9730 - val_loss: 0.1376 - val_accuracy: 0.9615\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0632 - accuracy: 0.9798 - val_loss: 0.1387 - val_accuracy: 0.9602\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0481 - accuracy: 0.9843 - val_loss: 0.1274 - val_accuracy: 0.9658\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 0.1376 - val_accuracy: 0.9646\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.1825 - val_accuracy: 0.9561\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.1382 - val_accuracy: 0.9682\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2894 - accuracy: 0.9164 - val_loss: 0.1616 - val_accuracy: 0.9532\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1205 - accuracy: 0.9648 - val_loss: 0.1055 - val_accuracy: 0.9690\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0784 - accuracy: 0.9760 - val_loss: 0.0908 - val_accuracy: 0.9731\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9830 - val_loss: 0.0921 - val_accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 0.0845 - val_accuracy: 0.9759\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.0833 - val_accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.0870 - val_accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0847 - val_accuracy: 0.9775\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.0958 - val_accuracy: 0.9754\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0845 - val_accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Plotting a validation accuracy comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a9c024da60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABH60lEQVR4nO3dd3gU5fbA8e+hVwHBShAQEaQlQECkiYKKiihYwI5gwYZe71Wxo/68ongtXLly0YsooigKAREBQaogECBB6b2XgNKLKef3xzsJm2STLCGb3STn8zz7ZHennZmdzJl55533FVXFGGOMyahYqAMwxhgTnixBGGOM8csShDHGGL8sQRhjjPHLEoQxxhi/LEEYY4zxyxJEEIjI/4nIXhHZ5X3uJiJbReSwiDQNYVxBiUNELvDmWTyv5pnD8kaIyP/lx7JOhYhsEpFOoY4jN3xjF5HnReSTQMbNxXLaicjq3MZp8pcliFzw/kGOeQfF1NeH3rAawN+BBqp6rjfJO8BjqlpBVZeexnJVRC46jdDzJI6MVHWLN8/kvJqnCR1V/aeq3p8X88q4z6rqHFWtlxfzNsFXItQBFGA3qOo0P9/XBPap6p4M3y3Pn7CyFS5xGFOoiEgJVU0KdRx5za4g8pB32f0TcL53VfGViBwGigPxIrLeG+98EflORBJEZKOI9POZR3HvEn+9iBwSkcUiUkNEZnujxHvz7uFn+cVE5EUR2Swie0TkcxGpJCKl/cXhZ3oVkb4islZE/hSRISIi2c3bG1bLm7aE97mXiGzw4t8oInf6LKO3iKz05j9FRGpmsz3bisg8EdnvFY318hlcRUR+8JaxQETq+Ez3gTf+QW/7tfMZNkBEvvHiPyQiy0Uk2mf4JhH5h4gsE5EDIvK1iJTxGd5FROK8mOaJSJMsYm8pIrFeDLtF5N1s1vMBEVknIn+IyAQROT+Q3yTDPM73rmrP9PmuqbiizpIiUkdEfhaRfd53o0SkchbxDBCRL3w+3+397vtE5AU/6znf2x47ReRDESnlDcu0z4pIBxHZ5jP9JSIy05t+uYh09Rk2wltfv7+zn7jHiMgu73ebLSINfYaVFZF/eetxQETmikhZb5jf/cyL636fefQSkbkZfptHRWQtsNb7Lrt9L6v/7SEi8q8M6/K9iDyZ1brmG1W11ym+gE1ApyyGdQC2ZfhOgYu898WAxcDLQCngQmADcI03/GngN6AeIEAkUDXjfLJYdm9gnTfPCsBYYKS/OLKYXoGJQGXgAiAB6JzTvIFa3rQlgPLAQaCeN+w8oKH3/iZvHpd4474IzMsilguAQ8DtQEmgKhDlDRsB/AG09OYzChjtM+1d3vglcMV9u4Ay3rABwHHgOlzCfBP4NcNvuxA4HzgTWAn09YY1A/YAl3rT3uuNXzrjfgHMB+723lcAWmWxnlcCe715lwb+DcwO5DfxM6+fgQd8Pg8ChnrvLwKu8pZxFjAbeN/fPu1toy+89w2Aw0B7b9p3gSSfcZsDrbxtXcvbXk9mtc/h8//h/a7rgOdx/wtXer956r6T7e+cxf5f0YvzfSDOZ9gQYCZQ3fvtWnvjZbefzQTu95lHL2BuhnX7CbeflA1g3/P7v+2t3w6gmDdeNeAocE7Ij3WhDqAgvrx/psPAfp/XAxn/ATLsSKkJ4lJgS4bhzwGfeu9XAzdmsdycDvDTgUd8PtcDEoESAU6vQFufz98A/XOaN5kTxH7g5tR/Gp9pfgT6+Hwu5v0j1PQTy3PAuCziHAF84vP5OmBVNuv1JxDpvR8ATPMZ1gA4luG3vcvn89ucPMh+BLyeYd6rgct9pk09cM4GXgWq5bAv/Q942+dzBW+71srpN/Ezr/uBn733AmwF2mcx7k3A0gzr7S9BvEz65Fse+IusT5Ce9P3dMu5zpE8Q7XAH0GI+w78CBuTmd84QR2Vv2ZW8/exY6j5wCvvZTHJOEFfmEIfvvpfd//ZK4Crv/WPApEDWM9gvK2LKvZtUtbLP6+MAp6uJK4Lan/rCnUGd4w2vAfgtAgrA+cBmn8+bcQftc/yP7tcun/dHcQesgOetqkeAHkBfYKdXPFDfG1wT+MBnvf/AHciq+4kjp+2QVZyIyN/FFWMd8JZTCXdWltW0ZcQrHsth3jWBv2f47Wrgtk1GfYCLgVUiskhEumSxHum2q6oeBvaRfptkua4ZfAtc5hVRtccdwOYAiMjZIjJaRLaLyEHgC9Jvk6ycj0s0qfEd8eLDm+/FIjLRK9o5CPwzwPmmzVtVU3y+20wu1t0rvhnoFd8cxCU8vFiqAWXwvz+dzv8b+GwbL47s9r3slvUZ7uoD7+/I04gpz1iCyH9bgY0ZkktFVb3OZ3iW5aw52IE7iKW6AFccsDv34Z76vFV1iqpehSteWgWkJs+twEMZ1r2sqs7zs7xcbQevzPdZ4DagiqpWBg7gEtHp2gq8kSH+cqr6VcYRVXWtqt4OnA28BXwrIuX9zDPddvXGqQpsP9XgVHU/MBW37ncAX6l3SoorSlOgiaqegTsIBbJNduIObKnxlfPiS/UR7jeu6833+QDnC27da4iI73HoAnKx7rj1vRHohDso10oNGVeEdxz/+1N2+9kRoJzP53P9jJO6fQPZ97Jb1hfAjSISiSuCjclivHxlCSL/LQQOisiz3o2z4iLSSERaeMM/AV4XkbriNBGR1H/I3bh7AFn5CvibiNQWkQq4s7mvNW9qVwQ0bxE5R0S6ege6E7iiuNTqr0OB51JvHoq7gX5rFssbBXQSkdtEpISIVBWRqADirIhLXAlACRF5GTjj1FY1Sx8DfUXkUu+3KS8i14tIxYwjishdInKWd3a83/vaXzXgL4H7RCRKRErjtusCVd2Uyxi/BO7BFfF96fN9RbxiURGpjisPD8S3QBfvRm4p4DXSHzcq4u45HfauFB/OMH12++wC3EH4GXE30jsANwCjA4zNV0Xc/rYPd1D/Z+oA7zcYDrwr7mZ+cRG5zNve2e1ncUB3ESknrqpunwBiyG7fy/J/W1W3AYtwVw7fqeqxXGyDPGcJIve+l/TPQYwLZCJ1zwrcAEQBG3FnN5/gznrA3QT8BncmeBBXRl3WGzYA+Mwr3rjNz+yH43aw2d68jwOPn/qq+RXovIvhbs7twBUhXQ48AqCq43Bn06O9YoDfgWv9LUxVt+DKnP/uzScOd1MvJ1Nw9zrW4IorjpOhGCC3VDUWeAD4EFe2vA5XLu1PZ2C5uNpjHwA9VfW4n3lOB14CvsOdrdcBep5GmBOAusBuVY33+f5V3I3wA8APuEoGOVLV5cCjuGSzE7fe23xG+Qfu7P0QLoF+nWEWA8hin1XVv4CuuH1gL/Af4B5VXRVIbBl8jvu9twMrgF8zDP8H7gbxItz+9Bbu3kd2+9l7uPstu3FFQKNyiCGnfS+7/228ZTQmTIqXAOTkFagxxphQEZH2uKKmWhnuy4SMXUEYY0yIiUhJ4Alcra2wSA5gCcIYY0JKRC7B3ac6D/f8RtiwIiZjjDF+2RWEMcYYvwpVY33VqlXTWrVqhToMY4wpMBYvXrxXVc/yN6xQJYhatWoRGxsb6jCMMabAEJHNWQ2zIiZjjDF+WYIwxhjjV1AThIh0FpHV4tq67+9neBURGSeu7f2FItLIZ9jfxLUP/7u4fhXKZJzeGGNM8AQtQYjrn3gI7jH6BsDtItIgw2jP49psb4JrP+YDb9rqQD8gWlUb4dpvP53mB4wxxpyiYF5BtATWqeoGr82V0bjWFn01wPUzgNf+Si0RSW0+ugRQVlwzzOVwbfsYY4zJJ8FMENVJ31DVNjK3+x8PdAfXdSGu2eMIVd0OvANswTUQdkBVp/pbiIg8KK5rx9iEhIQ8XgVjjCm6gpkg/LUJn/Gx7YG4voXjcC2DLgWSRKQK7mqjNq5TkfIichd+qOowVY1W1eizzvJbldcYY0wuBDNBbMOnoxEgggzFRKp6UFXvU9Uo3D2Is3BNSXfCdaqToKqJuKaJWwcxVmOMKZBmzoRkfz2N5IFgJohFQF2vg5lSuJvME3xHEJHK3jBw/enOVtWDuKKlVl5HHQJ0xPXZaowxRdrevTB8OBw44D4vWgTz5wdnWUF7klpVk0TkMVwnGsWB4aq6XET6esOH4rrW+1xEknGdfPTxhi0QkW+BJbgempYCw4IVqzHGhLOtWyEmBsaNg1mzICUFKlWCm2+Gxx6DUqVynEWuFKrWXKOjo9Wa2jDGFAYnTkDp0rBhA9TxerJu0AC6d4du3aBpU5A86GldRBararS/YYWqLSZjjCmoVCEuzl0ljB0LUVHwxRdw4YXw4YfQsSPUr5+/MVmCMMaEVGIilCzp3i9eDBs3wr59J19VqsCLL7rhN9zgytsPH4aLLnIH0Y4d4b77QhZ+nhg0CP7zH9i0CYoVg3btoEOHk8MffTQ0cVmCMMbkmUOHYPfu9Af4Y8fgwQfd8EGDYMqU9MPPPtslBYDnn4epPk88lSsHLVueTBDNm0NEhPt+9WpXHn/8+MkE0aIFVKvmEkdkpPtbty4UL55fWyBnf/0FM2bApEnwr39BiRLw55/QsCG89JJLguFSY98ShDFh5K+/YMcO+OMPd9BIfXXuDDVqwJo18M03mae7+26oWRN++w3Gj888vE8fOO88WLLEHZgyeuQROPNMd3Y+fXrm4U88ARUruiqVEyemP8D/8Qf8/rs7CD/zDAwdmn7akiXhgQdcefn+/XD0qDvIR0ZC1apQ3efx2ffeg6Qk933VqlAmQwtsAwb432bgrkQaNHDFNNOmufmkxv7++274xx+7pNG4sVuf/HL0KEye7IqOJk50NZDKl3eJs2FD+Oc/8y+WU2EJwpg8pAoHD548sKce6Js0gYsvdrVR3ngj/bA//4R33nE3Hn/5Ba68MvN8Y2Jcgli1yp1lZtSunUsQy5b5H37ddS5BLFrkf3iPHi5B/PKL/+F9+rgD6owZ8NFHbtzUg3jjxu6GarlycNddcNllJ4elvlK98Ub2269BxtbaApBag6dkSfjsM/f+xAlYuRLi46FePffdqlXpi2ouusglqb/9Ddq0cTWDRPLmxi+43zUx0V0h/fqrq3F05pknbzJfdVXmBBhurBaTMdnYvt0VZZx7rjt4HTsGr72W/uz+zz/h/vvhoYdcGXLt2pnn8+677kC0Zo07mFepcvJVuTI8/LD7fvdud4bvO/zMM91BplQpdxBLSck8/+LF3YEtP4YXK6CdBKjCtm0uacTFnfz74YdwzTWu6Ov229MXT0VGujP81HskOdm162R11J9/hiefdMVqSUkwZ477jUuE2Wl5drWYLEEY40PVFQH89JMrpljpPZ752GPw73+7M9MKFdIfwKtUcUU8d9zhEshHH2UefsEFLhGY8LV0qSsei493V2LHjrnv4+Jcopgzx12BRUa6V7Vq6ae//nr48Ue3D9Wt664SevZ01VHDmSUIY7KQmAgLFsDOnXDrre67OnXc5/btoVMnd2O0Th13kAd3AMirYggTnpKTYd06lxy6dXNXby++mL6IrHp1d5UxcaL7/PLL7kqje3d3tVlQ9hFLEMb4WLvWFeNMm+Zuuh4+DOec45KCiCsGqlnTPaRkjK+EhPRFVHv2wJgxcMYZoY4s9+xBOVOk7djhaub07OnO8D76yNWWuegiVzTUqRNcccXJM76LLw5tvCZ8nXWW2186dQp1JPnDEoQpdA4fdlcG06a5ewkrVrjv69SB1q3djcN+/aBWrRAGaUwBYAnCFHiJie7m4dlnu6uCRYvcw0Zlyrj7CL16uTO+yEg3fuq9BGNM9ixBmAJH1dVpT71CmDnTPcH77LMwcKC7Spg+3f0N93rmxoQzSxCmQNi1y9Vhj452dfEvu8w9jVqnjqte2qnTyQfMSpf2/7CZMebUWIIwafbtc7UxSpZ0Z+BDh7qHeooXd39LlHAPiZ1/vmsD5/vvMw/v18+1U79ggXulfp86Ts+e7gD++++uGmHq8NRxLr/cPYi1ebMbZ9o09/r9d9eS5cqVbrxvvnF1zf09lGaMyRuWIIq4Eyfghx9g5Ej3d9w498DPn3+6m7tJSe6VnOz+9u/vplu2zCUQ3+EAvXu7BDF5sv92c7p1cwlixAjXUFlGqfN5803473/duO3auSYcrrrq5HhXX52XW8EY4489B1FEHToETz/tzsT//NM9B3DHHa7Jh7p1T31+qiebYRBxLWwePXoygaS+atVy4+zY4ZqVSE08qa/UJo6XLXNtFV16KZQtm5drbozxZc9BGMAV6axdC9de61qSnD3bNeJ2112uDP902ogRSd+kcpky2d8gPv9898pKkya5j8UYkzcsQRRy+/a5q4TPP3ctSp57rmuArlgxV65fUBteM8YEnx0eCrEPP3RNPD/yiHt47K233DMCqUnBkoMxJjt2BVFIqMK8ee5m88MPu4fCmjaFxx93zUlERhacxsOMMeEhqAlCRDoDHwDFgU9UdWCG4VWA4UAd4DjQW1V/F5F6wNc+o14IvKyq7wcz3oJo3TqXFL74AjZscJ22tG3rEkKbNu5ljDG5EbQEISLFgSHAVcA2YJGITFDVFT6jPQ/EqWo3Eanvjd9RVVcDUT7z2Q6MC1asBU1ysrshfPw4NGvmio86doRXXnHVSPOzK0VjTOEVzCuIlsA6Vd0AICKjgRsB3wTRAHgTQFVXiUgtETlHVXf7jNMRWK+qm4MYa9g7ccK1Oz9ypOu2MjbW1RIaPdrV+ImICHWExpjCJpi3KasDW30+b/O+8xUPdAcQkZZATSDjoa4n8FVWCxGRB0UkVkRiExISTjvocLNsmevK8txz4ZZb3NPJHTqc7Kj9uussORhjgiOYCcLfLdGMT+UNBKqISBzwOLAUSEqbgUgpoCswJquFqOowVY1W1eizzjrrtIMOB2vXuuqpAL/95u4vXH+9ezp561b3BLJ1ZmOMCbZgJohtQA2fzxHADt8RVPWgqt6nqlHAPcBZwEafUa4FlmQociqUVOGTT1wjdBdfDMOHu+9vucU1VPfFF65j9XDr8NwYU3gFM0EsAuqKSG3vSqAnMMF3BBGp7A0DuB+YraoHfUa5nWyKlwqTIUPggQfcDee333bNXoC7UrCbzsaYUAja+aiqJonIY8AUXDXX4aq6XET6esOHApcAn4tIMu7mdZ/U6UWkHK4G1EPBijFc/P47/OMf7n7CxIn2vIIxJnCqrt2z8uXzft5BLbBQ1UnApAzfDfV5Px/w2zScqh4FqgYzvnBRtSp07+76SbbkYIwJlKprdHPmTPeqUCFv52+NLYSYqmsO48svXYuqxhgTqIEDXaWVVq2CcwVhCSKEJk92ragWwtq5xpggGzoUnn/e3a8cPDg4pQ9WJyZE9uyBXr3grLPsJrQx5tSMHu0a4bz+etf5VrAa3rQEEQKq0KcP7N8PP/2Ufb8Jxhjja9Ik1wBnu3YwZozrIjhYLEGEwEcfudpKH3wAjRuHOhpjTEExd657NqpxY5gwIfi9Ldo9iHyWlOT6abj2WtcUtzHGBCIuDrp0gRo13P3LSpWCv0y7gshnJUrA/PmuLSWr0moKiuRkV9Mu9WZoRIQ7UGX8e/75wS3yKKrWrnUtKVSs6Iqlzz47f5ZrCSIfTZjgfuT8yPzG5IXkZPj6a3j1VVizBho1cklg9WqYNg0OHUo/vohrWDIiwpJIXtm2Da66ClJSXHK44IL8W7YliHwydSrceCO88YarmmZMOEtOdjdAX3sNVq50ieHbb11/I741Zg4edAewrVsz/w0kifhLIBERlkRS7d0LV18Nf/wBM2ZA/fr5u3xRzdjAasEVHR2tsbGxoQ4jk4QE12dD1aquT+hg31gyJrdSUlwiePVVWLECGjZ0HVHdfHPuq1IePOg/gaT+3brVtUHmKzWJpCaMjEmkdm2XRAqzQ4fgyitdi85TpsDllwdnOSKyWFWj/Q2zK4ggS63S+scf7ke25GDCUUoKjB3rEsPvv8Mll7i69rfeevp17M84wyWahg2zHufAgawTyMqV7go8YxJ58kl46y0oVcrvLAu048ddicPSpTBuXPCSQ04sQQTZf/8L33/v2llq0iTU0RiTnirExMCAAa5zqnr1YNQo6NHDdWubXypVcq+skohq+uKs77+H9993FT6+/hpq1sy/WIMtKQl69nRFSiNHwg03hC4Wq+YaZO3bwxNPQL9+oY7EmJNUYfx416d59+5w7Jg7GC1f7ppuyM/kEAiRkwmkc2fXPP6337qri6ZN3XNFhUFKCtx/v/ttBg+Gu+4KbTyWIIIkJcX9bdDAnekE61F4Y06Fqjv7jo6Gm25y5dyffebuN9x1V/glhuzcfDMsXuyuHm64Afr3d2ffBZUqPPWU+z1efTU8npOyw1aQPP20exw+OTnUkRjjDj4//AAtW0LXrq6Zl08/hVWr4J57Cm5PhRdd5IqZ+vZ19yOuuAK2bw91VLnzf//nWld44gl46aVQR+NYggiCn36Cd991N+cK0hmZKXxU3VO3rVq5p3D37oX//c8lhl69Cm5i8FWmjGu+ZtQod1M3Ksrd1C5IPvwQXn7ZJet33w2fh2gtQeSxvXvh3ntdLZBBg0IdjSmqVN1BsnVr16zLrl0wbJh7NqF378L5jMEdd0BsrOtXpXNnVz23IFzBjxrlipO6dnXJO5yKo8MolIJP1d1g2rfPNUtQrlyoIzJFjap7OK1dO/fU/vbtrt+AtWtdn+eFsUqor/r1YeFCd3X02mvuIbNdu0IdVda+/96dUF5xhauNFW5XdJYg8tDGjTBrFrz5prvMNSY/zZjh6stfdRVs3gz/+Y9LDA89VPgTg69y5WD4cPeaP9/Vcpo5M9RRZTZrFtx2m4tv/PjwbPY/zPJVwXbhha7aXX41pGWC688/4YUXXLl2jRqutswFF7hX6vsqVUJfXjxrlitOmTXLPV384YfuSrZ06dDGFWr33edqa916K3TsCK+/7mo6hUMRzpIlruZV7drw44/h22mYJYg8cOKEe+r07rtd8wCmYFN17RD16+fuKbVpA/Hxrjjg+PH041aocDJp+CaO1PfBbFNozhyXGGbMcPvdBx/Agw+G55loqDRu7Jq36dvXJfs5c9zzHtWqhS6mVatc8d+ZZ7r7RKGMJSdBTRAi0hn4ACgOfKKqAzMMrwIMB+oAx4Heqvq7N6wy8AnQCFBv2PxgxptbL74I77wDdepA27ahjsacjq1b4dFHXTJo3tyd3TVt6oapuna1tmxxr82b079fvDhz/+LFikH16lknkAsucLXdTsW8eS4xTJvmbsi+954rRrJmXPyrWBG++OLkQ6tRUa68v02b/I9lyxZ3X6RYMVfbMSIi/2M4FUFrrE9EigNrgKuAbcAi4HZVXeEzziDgsKq+KiL1gSGq2tEb9hkwR1U/EZFSQDlV3Z/dMkPRWN+0aa7Mt29fV9XOFEzJye73e+4595Dja6+5g8mp3jQ8etQlGX8JZMsWNywxMf00lStnn0DOPddVl/71V5cYpk51xZjPPuv2O6sMEbilS12R06ZNMHAg/P3v+VdEuGePqzywe7e7JxIu9ymza6wvmAniMmCAql7jfX4OQFXf9BnnB+BNVZ3rfV4PtAaOAfHAhXoKAeZ3gti3z13CVqrkzh7tH7VgWr7cldn/+qs7uxs61JUNB0NKiqtVk1UC2bLF3fvwVbKku1LYts0VRzzzjOuwvnz54MRY2B044BrQ/O47V7V0xAh3LynYy7ziCle8NHVqeJU0hKo11+rAVp/P24BLM4wTD3QH5opIS6AmEAEkAwnApyISCSwGnlDVIxkXIiIPAg8CXJCfPWngLuv37nVPqBaW5JCYCAsWuAerwq3KXV47ccL1zzFwoCvmGTkS7rwzuGeUxYq5+xLnn++2sT+pzWP7Jo0tWyAyEh5+2N33MLlXqZK7x/Thh+4KomlT+OYb95R5MBw75hLRb7+5TsPCKTnkSFWD8gJuxd13SP18N/DvDOOcAXwKxAEjccVQkUA0kARc6o33AfB6Tsts3ry55qcZM1Q//jhfFxlUhw+rdu6sCqq1a6t+9JHqsWOhjio45sxRrV/fretdd6nu2RPqiEwoLFigWrOmasmSqoMHq6ak5O38//pLtUsXVRHVr77K23nnFSBWszqOZzXgdF/AZcAUn8/PAc9lM74Am7ykcS6wyWdYO+CHnJaZXwnixIl8WUy+SkhQbdlStVgx1f79VS+91O0d556r+vbbqgcPhjrCvLF/v+pDD7l1q1VLdfLkUEdkQm3fPtUbbnD7xC23uH0kLyQnq955p5vvRx/lzTyDIVQJogSwAagNlMIVJzXMME5loJT3/gHgc59hc4B63vsBwKCclpkfCeLECdXoaNV//jPoi8o3mzap1qunWqaM6rhx7ruUFNWff1bt1MntJZUrq770kkskBdXYsarnneeS4FNPuSsmY1Td/j5okGrx4qp16qguWXL683vsMfe/E+7HipAkCLdcrsPVZFoPvOB91xfoqyevMtYCq4CxQBWfaaOAWGAZEOM7LKtXfiSIZ55xWy31QFrQLVumev75LgHMnu1/nIULVbt1c+tdrpzqk0+qbt2av3Geju3bT8YfGam6aFGoIzLhau5c1erVVUuXVv3vf3Nf5PTyy25/+8c/8r7YKq+FLEHk9yvYCWL6dFeW+OCDQV1Mvpk1S7VSJZcgfvst5/GXL1e95x53llWypGqfPqpr1gQ9zFxLTnaX9mec4a6OBg50ZcLGZGfPHtWrr3ZHxzvuUD106NSmf+89N22fPuGfHFQtQeSJvXvdmUW9eoWjaGLsWHeWVK+eK2I6FRs3qj76qJu+WDHV225TXbo0GFHm3sqVqm3buj38yitV164NdUSmIElOVn39dbd/168f2AmUquqIEW6fu/lm1aSk4MaYVyxB5IGJE1UrVFBdvDhoi8g3Q4e6Hf/SS0/vnsKuXe6GdsWKbk+69lpXOyiUTpxQfe011VKlVKtUUR0+vGCcxZnw9PPPqueco1q2rDv4Z2fcOHd13amT6vHj+RJenrAEkUf++COosw+6lBTVV191v/p11+XdldCff6q+8YZqtWpu3m3bqk6alP8H5nnzVBs2dDH06OESmDGna+dO1Q4d3H51332qR45kHmf6dHdScumlp14kFWqWIE7DmjWqY8bk+WzzXVKSat++7he/997glMUfOeLqkteo4ZYTFaX69dfBv9Q+eNDVGBFxy544MbjLM0VPUpKrxSei2qiR6qpVJ4ctXOhKFxo1clVmCxpLELmUWqX1zDPdWXJBdeyYavfu7td+9tngn9mfOOGKdurVc8usW1f1k0+C8/zIhAmqERHuH7dfv8LzvIYJT5MnuyvlChVUv/zSVdyoWtU9WLp9e6ijyx1LELnUv7/bQmPH5uls89X+/aqXX+7W47338nfZSUnu6qtZM7f86tVdDHlRtLVzp7s5Du7Mbf7805+nMYHYulW1TRu371Ws6B4mXbcu1FHlniWIXJgxw52VPvBAns0y3+3Y4er9lyypOmpU6OJISXFnXqmJqmpVdyM5N/d0UlLc1Ujlyq7M9/XXC+eT7Sa8/fWXeybqwgvds0QFWXYJImituYZCXrXmeuSI69u2XDnX81NBbDVzzRrXKUlCAowd61opDQfz5rkuWSdOdI3OPfww/O1vcN55OU+7dq3rEGfmTNe2/7BhUK9e0EM2plDLrjXXMOh8L/yULw9vvQVfflkwk8OiRa4zlMOHXW9j4ZIcAFq3dp3xxMe7Lhf/9S/XtPbDD8OGDf6nSUx0SaVxY9ee/7Bhbr0sORgTXJYgMjjiNSh+xx2uR7GCZsoU1+58hQrwyy/QokWoI/KvSROXgFevhnvucR3MX3wx3HUX/P77yfEWLXL9Cj//PHTp4vr8fuCB8OhX2JjCzv7NfKxd685mJ0wIdSS5M2qUO4hedJEryrn44lBHlLOLLnJXBBs2uB7cYmLclcKNN8Jjj7k+E/buhXHj4NtvAyuKMsbkDUsQnsRE11lMUhI0axbqaE7du++6s++2bWHWrIJ3IK1e3RU3bd4MAwa4zuWHDHGdMq1YATfdFOoIjSl6CnmfYYEbMMAVZ3z7bfh3JO4rJQX694dBg+CWW1yvaGXKhDqq3Kta1fW7/Pe/u643a9QIdUTGFF2WIHBn3G++6fqpvfnmUEcTuMREF/PIka6P4sGDXef2hUGFCta1pjGhZkVMuM7qL74Y3n8/1JEE7sgRV04/ciS89prrX7ewJAdjTHiwBAE8+6x73qGgnLHu3QsdO7oaS8OGwUsvgUioozLGFDY5JggR6SIihT6RlCsX6ggCs3mzuxEdHw/ffeeqfBpjTDAEcuDvCawVkbdF5JJgB2Sy9ttv7kGz3bth6lSr2WOMCa4cE4Sq3gU0xfUr/amIzBeRB0WkYtCjM2nmzIF27TK/N8aYYAmo6EhVDwLfAaOB84BuwBIReTyIsRlPTAxcdRWce657AK5Ro1BHZIwpCgK5B3GDiIwDfgZKAi1V9VogEvhHkOMr8oYNc1Vvo6Jg7lyoWTPUERljiopAriBuBd5T1SaqOkhV9wCo6lGgd3YTikhnEVktIutEpL+f4VVEZJyILBORhSLSyGfYJhH5TUTiROT0m2gtYFRd9dWHHnKtsk6fDtWqhToqY0xREsiDcq8AO1M/iEhZ4BxV3aSq07OaSESKA0OAq4BtwCIRmaCqK3xGex6IU9VuIlLfG7+jz/ArVHVv4KtTOCQnw+OPw0cfuYbsPvkESpYMdVTGmKImkCuIMUCKz+dk77uctATWqeoGVf0Ld//ixgzjNACmA6jqKqCWiJwTwLwLrePHoUcPlxyeeQZGjLDkYIwJjUASRAnvAA+A975UANNVB7b6fN7mfecrHugOICItgZpAaktICkwVkcUi8mAAyyvwDhyAa691zze8+67rk8IegDPGhEogRUwJItJVVScAiMiNQCDFPv4ObRm7rxsIfCAiccBvwFIgyRvWRlV3iMjZwE8iskpVZ2daiEseDwJccMEFAYQVno4dgw4dXF8IX3zhWpY1xphQCiRB9AVGiciHuIP+VuCeAKbbBvi2xRkB7PAdwas+ex+AiAiw0Xuhqju8v3u8WlQtgUwJQlWHAcPAdTkaQFxhafJkiIuD0aNdEZMxxoRajglCVdcDrUSkAiCqeijAeS8C6opIbWA77onsO3xHEJHKwFGv2Op+YLaqHhSR8kAxVT3kvb8aeC3QlSqIYmKgSpWC1ZqsMaZwC6i5bxG5HmgIlBGvUFxVsz1gq2qSiDwGTAGKA8NVdbmI9PWGDwUuAT4XkWRgBdDHm/wcYJy3rBLAl6o6+RTXrcBISoKJE11vcCWsAXZjTJjI8XAkIkOBcsAVwCfALcDCQGauqpOASRm+G+rzfj5Q1890G3AP4hUJc+fCH39Y20rGmPASSC2m1qp6D/Cnqr4KXEb6ewvmNMXEQOnScPXVoY7EGGNOCiRBHPf+HhWR84FEoHbwQipaVGH8eNfWUkHpj8IYUzQEkiC+924mDwKWAJuAr4IYU5GybBls2uR6hzPGmHCS7T0Ir6Og6aq6H/hORCYCZVT1QH4EVxSMH+8ehrvhhlBHYowx6WV7BaGqKcC/fD6fsOSQt2Ji4LLL4Jwi3cCIMSYcBVLENFVEbhaxRh/y2pYtsHSp1V4yxoSnQGrdPwWUB5JE5DjuaWpV1TOCGlkRMH68+2v3H4wx4SiQJ6mta9EgGT8eLrkELr441JEYY0xmgTwo197f9/4azjOB+/NPmDkTnn461JEYY4x/gRQx+R7CyuAazVsMXBmUiIqISZNcx0B2/8EYE64CKWJKVwFTRGoAbwctoiIiJgbOOw9atAh1JMYY418gtZgy2gY0ynEsk6Xjx13z3l27QrHc/ALGGJMPArkH8W9OdvRTDIjC9QRncunnn+HwYau9ZIwJb4Hcg4j1eZ8EfKWqvwQpniJh/HjX7tKVdhfHGBPGAkkQ3wLHVTUZQESKi0g5VT0a3NAKp5QUmDDB9T1dunSoozHGmKwFUgI+HSjr87ksMC044RR+CxfCrl1We8kYE/4CSRBlVPVw6gfvfbnghVS4xcS4XuOuuy7UkRhjTPYCSRBHRKRZ6gcRaQ4cC15Ihdv48dChA1SuHOpIjDEme4Hcg3gSGCMiO7zP5wE9ghZRIbZ6NaxaBY89FupIjDEmZ4E8KLdIROoD9XAN9a1S1cSgR1YIpTbO17VraOMwxphA5FjEJCKPAuVV9XdV/Q2oICKPBD+0wicmBpo3hxrWo7cxpgAI5B7EA16PcgCo6p/AA4HMXEQ6i8hqEVknIv39DK8iIuNEZJmILBSRRhmGFxeRpV5PdgXarl3w66/2cJwxpuAIJEEU8+0sSESKA6VymsgbbwhwLdAAuF1EGmQY7XkgTlWbAPcAH2QY/gSwMoAYw97334OqVW81xhQcgSSIKcA3ItJRRK4EvgJ+DGC6lsA6Vd2gqn8Bo4GM588NcM9ZoKqrgFoicg6AiEQA1wOfBLQmYW78eKhdGxpZK1bGmAIikATxLO4g/jDwKLCM9A/OZaU6sNXn8zbvO1/xQHcAEWkJ1AQivGHvA88AKQEsK6wdPgzTprmrB+u41RhTUOSYIFQ1BfgV2ABEAx0JrNjH36FQM3weCFQRkTjgcWAprmvTLsAeVV2c40JEHhSRWBGJTUhICCCs/DdlCpw4YfcfjDEFS5bVXEXkYqAncDuwD/gaQFWvCHDe2wDf+joRwA7fEVT1IHCftzwBNnqvnkBXEbkO10nRGSLyharelXEhqjoMGAYQHR2dMQGFhZgYqFoV2rQJdSTGGBO47K4gVuGuFm5Q1baq+m8g+RTmvQioKyK1RaQU7qA/wXcEEansDQO4H5itqgdV9TlVjVDVWt50P/tLDgVBYiJMnAhdurgmNowxpqDILkHcDOwCZojIxyLSEf/FRn6pahLwGO4m90rgG1VdLiJ9RaSvN9olwHIRWYWr7fREblYinM2ZA/v3W+0lY0zBI6rZl8qISHngJlxR05XAZ8A4VZ0a9OhOUXR0tMbGxuY8Yj7q1w8+/hj27oXy5UMdjTHGpCcii1U12t+wQG5SH1HVUaraBXcfIQ7I9NCbyUzVVW+9+mpLDsaYgueUekRW1T9U9b+qan2hBSAuDrZssdpLxpiC6ZQShDk148dDsWJwww2hjsQYY06dJYggiomB1q3hrLNCHYkxxpw6SxBBsmkTxMdb7SVjTMFlCSJIUvt+sPsPxpiCyhJEkIwfDw0bwkUXhToSY4zJHUsQQfDHHzB7tl09GGMKNksQQfDDD5CcbPcfjDEFmyWIIIiJgerVXfeixhhTUFmCyGPHjrnmvbt2dc9AGGNMQWWHsDw2fTocOWLFS8aYgs8SRB4bPx7OOAM6dAh1JMYYc3osQeSh5GSYMAGuuw5Klcp5fGOMCWeWIPLQggWwZ49VbzXGFA6WIPJQTAyULAnXXhvqSIwx5vRZgsgjqi5BXHEFVKoU6miMMeb0WYLII6tWwdq1VnvJGFN4WILII6mN83XtGto4jDEmr1iCyCMxMdCihXuC2hhjCgNLEHlg505Xg8lqLxljChNLEHlgwgT31+4/GGMKk6AmCBHpLCKrRWSdiPT3M7yKiIwTkWUislBEGnnfl/E+x4vIchF5NZhxnq7x46FOHWjQINSRGGNM3glaghCR4sAQ4FqgAXC7iGQ8hD4PxKlqE+Ae4APv+xPAlaoaCUQBnUWkVbBiPR2HDrn2l266CURCHY0xxuSdYF5BtATWqeoGVf0LGA1kLKVvAEwHUNVVQC0ROUedw944Jb2XBjHWXJs8Gf76y+4/GGMKn2AmiOrAVp/P27zvfMUD3QFEpCVQE4jwPhcXkThgD/CTqi7wtxAReVBEYkUkNiEhIW/XIAAxMVCtGrRune+LNsaYoApmgvBX4JLxKmAgUMVLBI8DS4EkAFVNVtUoXMJomXp/ItMMVYeparSqRp911ll5FXtAEhNd73E33ADFi+froo0xJuhKBHHe24AaPp8jgB2+I6jqQeA+ABERYKP38h1nv4jMBDoDvwcx3lM2axYcOGC1l4wxhVMwryAWAXVFpLaIlAJ6AhN8RxCRyt4wgPuB2ap6UETOEpHK3jhlgU7AqiDGmisxMVC2LHTqFOpIjDEm7wXtCkJVk0TkMWAKUBwYrqrLRaSvN3wocAnwuYgkAyuAPt7k5wGfeTWhigHfqOrEYMWaG6queus110C5cqGOxhhj8l4wi5hQ1UnApAzfDfV5Px+o62e6ZUDTYMZ2upYsgW3b4PXXQx2JMcYEhz1JnUvjx0OxYtClS6gjMcaY4LAEkUsxMdCunaviaowxhZEliFzYsAF++80ejjPGFG6WIHIhte8HSxDGmMLMEkQujB8PjRvDhReGOhJjjAkeSxCnaO9emDPHHo4zxhR+liBO0Q8/QEqKFS8ZYwo/SxCnKCYGIiKgWbNQR2KMMcFlCeIUHD0KU6a4qwfr+8EYU9hZgjgF06bBsWN2/8EYUzRYgjgF48dDpUpw+eWhjsQYY4LPEkSAkpPh++/h+uuhZMlQR2OMMcFnCSJA8+dDQoLVXjLGFB2WIAIUEwOlSkHnzqGOxBhj8ocliACougRx5ZVwxhmhjsYYY/KHJYgArFgB69db7SVjTNES1A6DCovUxvluuCG0cYSjxMREtm3bxvHjx0MdijEmG2XKlCEiIoKSp1DLxhJEAGJi4NJL4fzzQx1J+Nm2bRsVK1akVq1aiD09aExYUlX27dvHtm3bqF27dsDTWRFTDrZvh0WLrPZSVo4fP07VqlUtORgTxkSEqlWrnvKVviWIHEyY4P7a/YesWXIwJvzl5v/UEkQOxo+HunWhfv1QR2KMMfkrqAlCRDqLyGoRWSci/f0MryIi40RkmYgsFJFG3vc1RGSGiKwUkeUi8kQw48zKgQPw88/u6sFOksNThw4dmDJlSrrv3n//fR555JFsp4mNjQXguuuuY//+/ZnGGTBgAO+88062y46JiWHFihVpn19++WWmTZt2CtEXXanbff/+/fznP/9J+37mzJl06dIlz5cXGxtLv3798ny+ENi+EkwVKlQI2ryDliBEpDgwBLgWaADcLiINMoz2PBCnqk2Ae4APvO+TgL+r6iVAK+BRP9MG3Y8/QmKiFS+Fs9tvv53Ro0en+2706NHcfvvtAU0/adIkKleunKtlZ0wQr732Gp06dcrVvEIlOTk5JMtN3e4ZE0SwREdHM3jw4KAvp7AJ5hVES2Cdqm5Q1b+A0UDGW70NgOkAqroKqCUi56jqTlVd4n1/CFgJVA9irH6NHw9nn+1qMJmcPfkkdOiQt68nn8x+mbfccgsTJ07kxIkTAGzatIkdO3bQtm1bHn74YaKjo2nYsCGvvPKK3+lr1arF3r17AXjjjTeoV68enTp1YvXq1WnjfPzxx7Ro0YLIyEhuvvlmjh49yrx585gwYQJPP/00UVFRrF+/nl69evHtt98CMH36dJo2bUrjxo3p3bt3Wny1atXilVdeoVmzZjRu3JhVq1ZlimnTpk20a9eOZs2a0axZM+bNm5c27O2336Zx48ZERkbSv7+7KF+3bh2dOnUiMjKSZs2asX79+kxn4o899hgjRoxIi+G1116jbdu2jBkzxu/6AezevZtu3boRGRlJZGQk8+bN46WXXuKDDz5Im+8LL7yQ6cD79ttvp333t7/9jSuvvDJtm9x1113ptnv//v1Zv349UVFRPP300wAcPnyYW265hfr163PnnXeiqpm2UYcOHXj22Wdp2bIlF198MXPmzAFcpYn77ruPxo0b07RpU2bMmAGkvzKZNWsWUVFRREVF0bRpUw4dOgTAoEGDaNGiBU2aNMlyf5k8eTLNmjUjMjKSjh07pn2/YsUKOnTowIUXXphue9x00000b96chg0bMmzYsLTvK1SowAsvvEBkZCStWrVi9+7dAPTq1Yt+/frRunVrLrzwwrT9KZD4du7cSfv27YmKiqJRo0Zp2+R0BDNBVAe2+nzeRuaDfDzQHUBEWgI1gQjfEUSkFtAUWOBvISLyoIjEikhsQkJC3kQO/PUXTJoEXbtC8eJ5NluTx6pWrUrLli2ZPHky4K4eevTogYjwxhtvEBsby7Jly5g1axbLli3Lcj6LFy9m9OjRLF26lLFjx7Jo0aK0Yd27d2fRokXEx8dzySWX8L///Y/WrVvTtWtXBg0aRFxcHHXq1Ekb//jx4/Tq1Yuvv/6a3377jaSkJD766KO04dWqVWPJkiU8/PDDfosmzj77bH766SeWLFnC119/nVY08uOPPxITE8OCBQuIj4/nmWeeAeDOO+/k0UcfJT4+nnnz5nHeeefluN3KlCnD3Llz6dmzp9/1A+jXrx+XX3458fHxLFmyhIYNG9KnTx8+++wzAFJSUhg9ejR33nlnunm3b98+7eAUGxvL4cOHSUxMZO7cubRr1y7duAMHDqROnTrExcUxaNAgAJYuXcr777/PihUr2LBhA7/88ovfdUhKSmLhwoW8//77vPrqqwAMGTIEgN9++42vvvqKe++9N1PNnXfeeYchQ4YQFxfHnDlzKFu2LFOnTmXt2rUsXLiQuLg4Fi9ezOzZs9NNl5CQwAMPPMB3331HfHw8Y8aMSRu2atUqpkyZwsKFC3n11VdJTEwEYPjw4SxevJjY2FgGDx7Mvn37ADhy5AitWrUiPj6e9u3b8/HHH6fNa+fOncydO5eJEyemnQQEEt+XX37JNddcQ1xcHPHx8URFRfndbqcimM9B+Cu1z3gqMBD4QETigN+ApbjiJTcDkQrAd8CTqnrQ30JUdRgwDCA6OjrzqUYuzZwJBw9a9dZT8f77oVluajHTjTfeyOjRoxk+fDgA33zzDcOGDSMpKYmdO3eyYsUKmjRp4ncec+bMoVu3bpQrVw6Arl27pg37/fffefHFF9m/fz+HDx/mmmuuyTae1atXU7t2bS6++GIA7r33XoYMGcKT3uVQ9+7dAWjevDljx47NNH1iYiKPPfYYcXFxFC9enDVr1gAwbdo07rvvvrQYzzzzTA4dOsT27dvp1q0b4A78gejRo0eO6/fzzz/z+eefA1C8eHEqVapEpUqVqFq1KkuXLmX37t00bdqUqlWrppt38+bNWbx4MYcOHaJ06dI0a9aM2NhY5syZE1AxT8uWLYmIcOeJUVFRbNq0ibZt22Yaz3c7btq0CYC5c+fy+OOPA1C/fn1q1qyZtv1StWnThqeeeoo777yT7t27ExERwdSpU5k6dSpNmzYF3FXM2rVrad++fdp0v/76K+3bt097juDMM89MG3b99ddTunRpSpcuzdlnn83u3buJiIhg8ODBjBs3DoCtW7eydu1aqlatSqlSpdKuaJo3b85PP/2UNq+bbrqJYsWK0aBBg7Qri0Dia9GiBb179yYxMZGbbrop7BPENqCGz+cIYIfvCN5B/z4AcXWwNnovRKQkLjmMUtXM/0VBFhMD5cuDz1WkCVM33XQTTz31FEuWLOHYsWM0a9aMjRs38s4777Bo0SKqVKlCr169cqwDnlU1wF69ehETE0NkZCQjRoxg5syZ2c7HX5GIr9KlSwPuoJuUlJRp+Hvvvcc555xDfHw8KSkpaQd9Vc0UY1bLKlGiBCkpKWmfM657+fLl096f6vrdf//9jBgxgl27dtG7d+9Mw0uWLEmtWrX49NNPad26NU2aNGHGjBmsX7+eSy65JNt5w8ntA1lvI9/xfMfJadsD9O/fn+uvv55JkybRqlUrpk2bhqry3HPP8dBDD2U5nb/tn13MM2fOZNq0acyfP59y5crRoUOHtN+hZMmSafPKuI6+80pdn0Dia9++PbNnz+aHH37g7rvv5umnn+aee+7JcXtkJ5hFTIuAuiJSW0RKAT2BCb4jiEhlbxjA/cBsVT3oJYv/AStV9d0gxuhXSop7/uGaa6Bs2fxeujlVFSpUoEOHDvTu3Tvt5vTBgwcpX748lSpVYvfu3fz444/ZzqN9+/aMGzeOY8eOcejQIb7//vu0YYcOHeK8884jMTGRUaNGpX1fsWLFtPJrX/Xr12fTpk2sW7cOgJEjR3L5KfQydeDAAc477zyKFSvGyJEj024kX3311QwfPjztHsEff/zBGWecQUREBDExMQCcOHGCo0ePUrNmTVasWMGJEyc4cOAA06dPz3J5Wa1fx44d04rGkpOTOXjQXcR369aNyZMns2jRoiyvptq3b88777xD+/btadeuHUOHDiUqKirTATarbZhb7du3T1uHNWvWsGXLFurVq5dunPXr19O4cWOeffZZoqOjWbVqFddccw3Dhw/n8OHDAGzfvp09e/akm+6yyy5j1qxZbNy4EXDbPzsHDhygSpUqlCtXjlWrVvHrr7/mer0CiW/z5s2cffbZPPDAA/Tp04clS5bkenmpgpYgVDUJeAyYgrvJ/I2qLheRviLS1xvtEmC5iKzC1XZKrc7aBrgbuFJE4rzXdcGKNaPFi90T1FZ7qeC4/fbbiY+Pp2fPngBERkbStGlTGjZsSO/evWnTpk220zdr1owePXoQFRXFzTffnK6s/PXXX+fSSy/lqquuor7PAzE9e/Zk0KBBNG3alPXr16d9X6ZMGT799FNuvfVWGjduTLFixejbty+BeuSRR/jss89o1aoVa9asSTvb79y5M127diU6OpqoqKi0+xcjR45k8ODBNGnShNatW7Nr1y5q1KjBbbfdRpMmTbjzzjvTiib8yWr9PvjgA2bMmEHjxo1p3rw5y5cvB6BUqVJcccUV3HbbbRTP4gZdu3bt2LlzJ5dddhnnnHMOZcqUyXT/Adw9pDZt2tCoUaO0m9Sn45FHHiE5OZnGjRvTo0cPRowYke6MHFw16EaNGhEZGUnZsmW59tprufrqq7njjju47LLLaNy4MbfcckumxHXWWWcxbNgwunfvTmRkZLpiOn86d+5MUlISTZo04aWXXqJVq1a5Xq9A4ps5c2bajffvvvuOJ544/acDJJBLsoIiOjpaU+u3n44XX4SBA2HPHvApZjR+rFy5MqBiA1N4pKSk0KxZM8aMGUPdunVDHY45Bf7+X0VksapG+xvfnqT2IyYG2re35GBMRitWrOCiiy6iY8eOlhyKAGvNNYN162D5cnjggVBHYkz4adCgARs2bAh1GCaf2BVEBql9P1j1VmNMUWcJIoPx4yEyEmrVCnUkxhgTWpYgfCQkwC+/WO0lY4wBSxDpTJzonoGw4iVjjLEEkU5MDFxwAeTBE+omn1hz3wVTfjf3HUy++1N+C/b2sgThOXoUfvrJXT1Y3w8FhzX3fXqKSnPfqbJqtsP4ZwnCM3UqHDtm9x9Ol78mu1P//48e9T/ca4WavXszD8uJNfdd9Jr73rFjR1pz3VFRURQvXpzNmzeTkJDAzTffTIsWLWjRokVaK7ADBgzgwQcf5Oqrr+aee+5h8+bNdOzYkSZNmtCxY0e2bNkCwJgxY9KesPZtBC/jumXc/qnTZmx6PKvfcebMmXTo0MHvOma1fxw5coTevXvTokULmjZtyvjU6pY+smrG/LSoaqF5NW/eXHOrVy/VypVV//or17MoklasWJHu8+WXZ34NGeKGHTnif/inn7rhCQmZhwXiuuuu05iYGFVVffPNN/Uf//iHqqru27dPVVWTkpL08ssv1/j4eC/Gy3XRokWqqlqzZk1NSEjQ2NhYbdSokR45ckQPHDigderU0UGDBqmq6t69e9OW9cILL+jgwYNVVfXee+/VMWPGpA1L/Xzs2DGNiIjQ1atXq6rq3Xffre+9917a8lKnHzJkiPbp0yfT+hw5ckSPHTumqqpr1qzR1P160qRJetlll+mRI0fSrV/Lli117Nixqqp67NgxPXLkiM6YMUOvv/76tHk++uij+qm3oWvWrKlvvfVW2rCs1u+2225LizspKUn379+vGzdu1KZNm6qqanJysl544YXppldVnT9/vt5yyy2qqtq2bVtt0aKF/vXXXzpgwAAdOnRouu2+ceNGbdiwYdq0M2bM0DPOOEO3bt2qycnJ2qpVK50zZ06mbZTqww8/1FtvvVVVVW+//fa0cTdv3qz169dXVdVXXnlFmzVrpkePHlVV1S5duuiIESNUVfV///uf3njjjaqq2qhRI922bZuqqv7555+ZlpXV9r/88sv1qaeeUlXVH374QTt27KiqWf+O2a1jVvvHc889pyNHjkyLrW7dunr48OF0v3OXLl107ty5qqp66NAhTUxMzLQOGf9fVVWBWM3imGoPygFJSfD999ClC5QsGepoCrbsGgItVy774dWqZT88K9bcd9Fs7vuXX37hk08+STtjnzZtWroiv4MHD6adRXft2pWyXsub8+fPT9vud999d1q/Gm3atKFXr17cdtttab+RL3/bP5W/psez+h1zWkd/+8fUqVOZMGFC2n2x48ePp135pPLXjPnpsgQBzJsH+/ZZ7aWCypr7zqywN/e9c+dO+vTpw4QJE9L6ZE5JSWH+/PlpiSCr9c0odZsOHTqUBQsW8MMPPxAVFUVcXFy65Odv+2eM2TferH7HnNYxq2bMv/vuu0wt06b2FwH+mzH3bXwxN+weBK72UunSrnlvU/BYc99Fq7nvxMREbrvtNt566620q7TU7fPhhx+mfY6Li/M7fevWrdMqNowaNSrtzH39+vVceumlvPbaa1SrVo2tW7emm87f9s9OVr9jblxzzTX8+9//TjshWLp0aaZx/DVjfrqKfIJQdU9Pd+wIFSuGOhqTW9bcd9Fp7nvevHksWrSIV155Je2m7I4dOxg8eDCxsbE0adKEBg0aMHToUL/TDx48mE8//ZQmTZowcuTItJvuTz/9NI0bN6ZRo0a0b9+eyMjIdNNltf2zktXvmBsvvfQSiYmJNGnShEaNGvHSSy9lGsdfM+anq8g39330KPTr5xJEgDUjjQ9r7rvosea+C65Tbe67yN+DKFcOPvkk1FEYUzCsWLGCLl260K1bN0sORUCRTxDGmMBZc99FS5G/B2FOX2EqpjSmsMrN/6klCHNaypQpw759+yxJGBPGVJV9+/YF/JxMKitiMqclIiKCbdu2kZCQEOpQjDHZKFOmzCk/PGcJwpyWkiVLUrt27VCHYYwJAitiMsYY45clCGOMMX5ZgjDGGONXoXqSWkQSgM2hjuM0VQP2hjqIMGHbIj3bHunZ9jjpdLZFTVU9y9+AQpUgCgMRic3qsfeixrZFerY90rPtcVKwtoUVMRljjPHLEoQxxhi/LEGEn2GhDiCM2LZIz7ZHerY9TgrKtrB7EMYYY/yyKwhjjDF+WYIwxhjjlyWIMCAiNURkhoisFJHlIvJEqGMKNREpLiJLRWRiqGMJNRGpLCLfisgqbx+5LNQxhZKI/M37P/ldRL4SkVNrorSAE5HhIrJHRH73+e5MEflJRNZ6f6vkxbIsQYSHJODvqnoJ0Ap4VEQahDimUHsCWBnqIMLEB8BkVa0PRFKEt4uIVAf6AdGq2ggoDvQMbVT5bgTQOcN3/YHpqloXmO59Pm2WIMKAqu5U1SXe+0O4A0D10EYVOiISAVwPFPnOYEXkDKA98D8AVf1LVfeHNKjQKwGUFZESQDlgR4jjyVeqOhv4I8PXNwKfee8/A27Ki2VZgggzIlILaAosCHEoofQ+8AyQEuI4wsGFQALwqVfk9omIlA91UKGiqtuBd4AtwE7ggKpODW1UYeEcVd0J7oQTODsvZmoJIoyISAXgO+BJVT0Y6nhCQUS6AHtUdXGoYwkTJYBmwEeq2hQ4Qh4VHxREXtn6jUBt4HygvIjcFdqoCi9LEGFCREriksMoVR0b6nhCqA3QVUQ2AaOBK0Xki9CGFFLbgG2qmnpF+S0uYRRVnYCNqpqgqonAWKB1iGMKB7tF5DwA7++evJipJYgwICKCK2NeqarvhjqeUFLV51Q1QlVr4W4+/qyqRfYMUVV3AVtFpJ73VUdgRQhDCrUtQCsRKef933SkCN+09zEBuNd7fy8wPi9mal2Ohoc2wN3AbyIS5333vKpOCl1IJow8DowSkVLABuC+EMcTMqq6QES+BZbgav8tpYg1uSEiXwEdgGoisg14BRgIfCMifXBJ9NY8WZY1tWGMMcYfK2IyxhjjlyUIY4wxflmCMMYY45clCGOMMX5ZgjDGGOOXJQhjciAiySIS5/PKsyeZRaSWb6ucxoQTew7CmJwdU9WoUAdhTH6zKwhjcklENonIWyKy0Htd5H1fU0Smi8gy7+8F3vfniMg4EYn3XqlNRBQXkY+9Pg6mikhZb/x+IrLCm8/oEK2mKcIsQRiTs7IZiph6+Aw7qKotgQ9xrdDivf9cVZsAo4DB3veDgVmqGolrT2m5931dYIiqNgT2Azd73/cHmnrz6RucVTMma/YktTE5EJHDqlrBz/ebgCtVdYPX2OIuVa0qInuB81Q10ft+p6pWE5EEIEJVT/jMoxbwk9fRCyLyLFBSVf9PRCYDh4EYIEZVDwd5VY1Jx64gjDk9msX7rMbx54TP+2RO3hu8HhgCNAcWex3kGJNvLEEYc3p6+Pyd772fx8luMO8E5nrvpwMPQ1qf22dkNVMRKQbUUNUZuM6TKgOZrmKMCSY7IzEmZ2V9WtkF1z90alXX0iKyAHeydbv3XT9guIg8jesNLrX11SeAYV6Lm8m4ZLEzi2UWB74QkUqAAO9ZV6Mmv9k9CGNyybsHEa2qe0MdizHBYEVMxhhj/LIrCGOMMX7ZFYQxxhi/LEEYY4zxyxKEMcYYvyxBGGOM8csShDHGGL/+H80h9N4t6k1XAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The nature of generalization in deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Fitting a MNIST model with randomly shuffled labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3178 - accuracy: 0.1011 - val_loss: 2.3064 - val_accuracy: 0.1021\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2997 - accuracy: 0.1179 - val_loss: 2.3190 - val_accuracy: 0.1040\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2907 - accuracy: 0.1275 - val_loss: 2.3133 - val_accuracy: 0.1042\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2766 - accuracy: 0.1412 - val_loss: 2.3253 - val_accuracy: 0.1047\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2595 - accuracy: 0.1554 - val_loss: 2.3330 - val_accuracy: 0.1031\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2375 - accuracy: 0.1692 - val_loss: 2.3509 - val_accuracy: 0.1033\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2145 - accuracy: 0.1841 - val_loss: 2.3623 - val_accuracy: 0.1057\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1863 - accuracy: 0.1990 - val_loss: 2.3784 - val_accuracy: 0.1023\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1569 - accuracy: 0.2157 - val_loss: 2.3928 - val_accuracy: 0.1048\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.1253 - accuracy: 0.2318 - val_loss: 2.4215 - val_accuracy: 0.1015\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.0934 - accuracy: 0.2491 - val_loss: 2.4417 - val_accuracy: 0.1037\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.0610 - accuracy: 0.2623 - val_loss: 2.4733 - val_accuracy: 0.0972\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.0254 - accuracy: 0.2778 - val_loss: 2.4976 - val_accuracy: 0.1014\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9921 - accuracy: 0.2926 - val_loss: 2.5248 - val_accuracy: 0.1002\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9569 - accuracy: 0.3071 - val_loss: 2.5511 - val_accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.9249 - accuracy: 0.3208 - val_loss: 2.5712 - val_accuracy: 0.1036\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.8913 - accuracy: 0.3354 - val_loss: 2.6184 - val_accuracy: 0.1006\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.8590 - accuracy: 0.3506 - val_loss: 2.6564 - val_accuracy: 0.1018\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.8248 - accuracy: 0.3596 - val_loss: 2.6821 - val_accuracy: 0.1007\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.7941 - accuracy: 0.3728 - val_loss: 2.7202 - val_accuracy: 0.1038\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.7624 - accuracy: 0.3859 - val_loss: 2.7414 - val_accuracy: 0.1009\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.7310 - accuracy: 0.3972 - val_loss: 2.7920 - val_accuracy: 0.1031\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.7004 - accuracy: 0.4088 - val_loss: 2.8186 - val_accuracy: 0.1060\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6724 - accuracy: 0.4209 - val_loss: 2.8829 - val_accuracy: 0.1029\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6442 - accuracy: 0.4313 - val_loss: 2.8924 - val_accuracy: 0.1023\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.6153 - accuracy: 0.4417 - val_loss: 2.9474 - val_accuracy: 0.1058\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.5861 - accuracy: 0.4531 - val_loss: 2.9824 - val_accuracy: 0.1058\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.5610 - accuracy: 0.4636 - val_loss: 3.0305 - val_accuracy: 0.0999\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.5358 - accuracy: 0.4694 - val_loss: 3.0731 - val_accuracy: 0.1058\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.5111 - accuracy: 0.4773 - val_loss: 3.1021 - val_accuracy: 0.1023\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4835 - accuracy: 0.4909 - val_loss: 3.1699 - val_accuracy: 0.1045\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4593 - accuracy: 0.4988 - val_loss: 3.1918 - val_accuracy: 0.0991\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4365 - accuracy: 0.5062 - val_loss: 3.2696 - val_accuracy: 0.1032\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.4139 - accuracy: 0.5167 - val_loss: 3.2911 - val_accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3903 - accuracy: 0.5253 - val_loss: 3.3072 - val_accuracy: 0.1023\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3685 - accuracy: 0.5340 - val_loss: 3.3666 - val_accuracy: 0.1011\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3446 - accuracy: 0.5410 - val_loss: 3.4275 - val_accuracy: 0.1007\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3241 - accuracy: 0.5513 - val_loss: 3.4792 - val_accuracy: 0.1058\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.3043 - accuracy: 0.5557 - val_loss: 3.5193 - val_accuracy: 0.1017\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2834 - accuracy: 0.5638 - val_loss: 3.5568 - val_accuracy: 0.1002\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2645 - accuracy: 0.5722 - val_loss: 3.5925 - val_accuracy: 0.1037\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2431 - accuracy: 0.5779 - val_loss: 3.6709 - val_accuracy: 0.1033\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2229 - accuracy: 0.5865 - val_loss: 3.7291 - val_accuracy: 0.1032\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.2049 - accuracy: 0.5936 - val_loss: 3.7731 - val_accuracy: 0.1003\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1865 - accuracy: 0.5981 - val_loss: 3.8094 - val_accuracy: 0.1002\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1677 - accuracy: 0.6061 - val_loss: 3.8483 - val_accuracy: 0.1034\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1501 - accuracy: 0.6115 - val_loss: 3.9220 - val_accuracy: 0.1053\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1324 - accuracy: 0.6186 - val_loss: 3.9913 - val_accuracy: 0.1039\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1160 - accuracy: 0.6240 - val_loss: 4.0156 - val_accuracy: 0.0989\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.1004 - accuracy: 0.6299 - val_loss: 4.0845 - val_accuracy: 0.1031\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0827 - accuracy: 0.6365 - val_loss: 4.1409 - val_accuracy: 0.1002\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0668 - accuracy: 0.6399 - val_loss: 4.2121 - val_accuracy: 0.1067\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0494 - accuracy: 0.6487 - val_loss: 4.2424 - val_accuracy: 0.1047\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0336 - accuracy: 0.6540 - val_loss: 4.3123 - val_accuracy: 0.1016\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0197 - accuracy: 0.6592 - val_loss: 4.3453 - val_accuracy: 0.1009\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 1.0034 - accuracy: 0.6626 - val_loss: 4.3970 - val_accuracy: 0.1031\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9897 - accuracy: 0.6684 - val_loss: 4.4557 - val_accuracy: 0.1048\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9762 - accuracy: 0.6743 - val_loss: 4.4993 - val_accuracy: 0.1065\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9608 - accuracy: 0.6792 - val_loss: 4.5624 - val_accuracy: 0.1007\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9449 - accuracy: 0.6840 - val_loss: 4.5886 - val_accuracy: 0.1017\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9340 - accuracy: 0.6881 - val_loss: 4.6772 - val_accuracy: 0.1038\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9199 - accuracy: 0.6943 - val_loss: 4.7316 - val_accuracy: 0.0998\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.9030 - accuracy: 0.6979 - val_loss: 4.8021 - val_accuracy: 0.1051\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8930 - accuracy: 0.7045 - val_loss: 4.8339 - val_accuracy: 0.1016\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8793 - accuracy: 0.7092 - val_loss: 4.8675 - val_accuracy: 0.1038\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8649 - accuracy: 0.7131 - val_loss: 4.9619 - val_accuracy: 0.1047\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8543 - accuracy: 0.7167 - val_loss: 5.0231 - val_accuracy: 0.1052\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8409 - accuracy: 0.7215 - val_loss: 5.0938 - val_accuracy: 0.1043\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8301 - accuracy: 0.7255 - val_loss: 5.1624 - val_accuracy: 0.0988\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8169 - accuracy: 0.7313 - val_loss: 5.2052 - val_accuracy: 0.1028\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.8070 - accuracy: 0.7326 - val_loss: 5.2566 - val_accuracy: 0.1051\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7934 - accuracy: 0.7376 - val_loss: 5.3350 - val_accuracy: 0.1061\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7849 - accuracy: 0.7420 - val_loss: 5.3711 - val_accuracy: 0.1024\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7731 - accuracy: 0.7452 - val_loss: 5.4340 - val_accuracy: 0.1031\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7594 - accuracy: 0.7517 - val_loss: 5.5254 - val_accuracy: 0.1050\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7514 - accuracy: 0.7533 - val_loss: 5.5540 - val_accuracy: 0.1044\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7403 - accuracy: 0.7560 - val_loss: 5.6155 - val_accuracy: 0.1032\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7298 - accuracy: 0.7602 - val_loss: 5.6816 - val_accuracy: 0.1035\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7203 - accuracy: 0.7643 - val_loss: 5.7489 - val_accuracy: 0.1032\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7090 - accuracy: 0.7688 - val_loss: 5.8551 - val_accuracy: 0.1022\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7023 - accuracy: 0.7703 - val_loss: 5.8299 - val_accuracy: 0.1055\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.7764 - val_loss: 5.9089 - val_accuracy: 0.1023\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6808 - accuracy: 0.7775 - val_loss: 5.9855 - val_accuracy: 0.1036\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6700 - accuracy: 0.7817 - val_loss: 6.0569 - val_accuracy: 0.1032\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6617 - accuracy: 0.7846 - val_loss: 6.1591 - val_accuracy: 0.0994\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6531 - accuracy: 0.7851 - val_loss: 6.1991 - val_accuracy: 0.1011\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6452 - accuracy: 0.7908 - val_loss: 6.2205 - val_accuracy: 0.1004\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6354 - accuracy: 0.7910 - val_loss: 6.3265 - val_accuracy: 0.1052\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6248 - accuracy: 0.7977 - val_loss: 6.3946 - val_accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6168 - accuracy: 0.8003 - val_loss: 6.4481 - val_accuracy: 0.1041\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.8022 - val_loss: 6.5438 - val_accuracy: 0.1016\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6000 - accuracy: 0.8060 - val_loss: 6.5790 - val_accuracy: 0.1037\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.8099 - val_loss: 6.6329 - val_accuracy: 0.1032\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5831 - accuracy: 0.8124 - val_loss: 6.6680 - val_accuracy: 0.1043\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5767 - accuracy: 0.8138 - val_loss: 6.7963 - val_accuracy: 0.1019\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.8155 - val_loss: 6.8366 - val_accuracy: 0.1036\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.8175 - val_loss: 6.8876 - val_accuracy: 0.1063\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.8215 - val_loss: 6.9524 - val_accuracy: 0.1066\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.8237 - val_loss: 7.0014 - val_accuracy: 0.1018\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.8255 - val_loss: 7.0613 - val_accuracy: 0.1071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a78c32d490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The manifold hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Interpolation as a source of generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Why deep learning works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training data is paramount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Evaluating machine-learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Simple hold-out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Iterated K-fold validation with shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Beating a common-sense baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Things to keep in mind about model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tuning key gradient descent parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a MNIST model with an incorrectly high learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1076.1730 - accuracy: 0.4099 - val_loss: 2.6454 - val_accuracy: 0.2562\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 5.6130 - accuracy: 0.2596 - val_loss: 1.9882 - val_accuracy: 0.2726\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5301 - accuracy: 0.2756 - val_loss: 2.2484 - val_accuracy: 0.2970\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.9354 - accuracy: 0.2689 - val_loss: 2.1950 - val_accuracy: 0.2412\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.6500 - accuracy: 0.2639 - val_loss: 1.9887 - val_accuracy: 0.2702\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.9021 - accuracy: 0.2797 - val_loss: 2.1238 - val_accuracy: 0.2812\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.4670 - accuracy: 0.2974 - val_loss: 2.2273 - val_accuracy: 0.2828\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.2364 - accuracy: 0.2915 - val_loss: 2.0148 - val_accuracy: 0.2703\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3973 - accuracy: 0.2738 - val_loss: 2.2225 - val_accuracy: 0.3021\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.5509 - accuracy: 0.2929 - val_loss: 2.1064 - val_accuracy: 0.3012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a78c596910>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The same model with a more appropriate learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3509 - accuracy: 0.9116 - val_loss: 0.1765 - val_accuracy: 0.9504\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9629 - val_loss: 0.2044 - val_accuracy: 0.9530\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1120 - accuracy: 0.9736 - val_loss: 0.1611 - val_accuracy: 0.9697\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9789 - val_loss: 0.1960 - val_accuracy: 0.9643\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9816 - val_loss: 0.2023 - val_accuracy: 0.9702\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9848 - val_loss: 0.2348 - val_accuracy: 0.9706\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0802 - accuracy: 0.9859 - val_loss: 0.2825 - val_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9872 - val_loss: 0.3206 - val_accuracy: 0.9726\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9883 - val_loss: 0.3320 - val_accuracy: 0.9702\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0598 - accuracy: 0.9896 - val_loss: 0.2968 - val_accuracy: 0.9738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a78c9ef3a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging better architecture priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Increasing model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple logistic regression on MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6667 - accuracy: 0.8388 - val_loss: 0.3565 - val_accuracy: 0.9062\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.9043 - val_loss: 0.3074 - val_accuracy: 0.9157\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3156 - accuracy: 0.9129 - val_loss: 0.2910 - val_accuracy: 0.9198\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.9164 - val_loss: 0.2804 - val_accuracy: 0.9221\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.9196 - val_loss: 0.2763 - val_accuracy: 0.9232\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.9211 - val_loss: 0.2732 - val_accuracy: 0.9247\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2781 - accuracy: 0.9226 - val_loss: 0.2693 - val_accuracy: 0.9254\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.9241 - val_loss: 0.2676 - val_accuracy: 0.9279\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.9249 - val_loss: 0.2690 - val_accuracy: 0.9267\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2689 - accuracy: 0.9258 - val_loss: 0.2652 - val_accuracy: 0.9272\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.9265 - val_loss: 0.2642 - val_accuracy: 0.9294\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9269 - val_loss: 0.2633 - val_accuracy: 0.9303\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2632 - accuracy: 0.9278 - val_loss: 0.2626 - val_accuracy: 0.9303\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2616 - accuracy: 0.9281 - val_loss: 0.2629 - val_accuracy: 0.9297\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.9283 - val_loss: 0.2612 - val_accuracy: 0.9312\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9292 - val_loss: 0.2641 - val_accuracy: 0.9285\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9297 - val_loss: 0.2624 - val_accuracy: 0.9296\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.9301 - val_loss: 0.2617 - val_accuracy: 0.9309\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.9297 - val_loss: 0.2620 - val_accuracy: 0.9317\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.9305 - val_loss: 0.2605 - val_accuracy: 0.9308\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a7a2b33be0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzLElEQVR4nO3dd5xU1f3/8deHpTc1gIYmIKC7ILLgikQUjRoVNXaDaBSswYSosWKKEo1+9Svf2EtsoEZF48+CPYaoYDSEIqC0CIiygnQEpMPn98e5ww7L7O5smb1b3s/HYx47e+tn7tyZz5xzzz3H3B0REZHC6sQdgIiIVE1KECIikpIShIiIpKQEISIiKSlBiIhISkoQIiKSUq1PEGb2JzNbYWbfRv+fbmaLzGy9mfWKMa5i44im75fhGPqZ2RfRvk4zs33MbLyZrTOz/zOz35rZ42ls5xEz+0MmY60MZjbEzD5Kc9nRZvanTMdUEczsbTMbHHccFcXMjjKz/KT/Z5rZUeksW4Z9ZeTcNrMRZvbXit5uadWNO4BMM7OFwD7A9qTJo919mJm1B64BOrj7smjeSGCYu79Wzv060NXd55VxE8XG4e5Nyxxc+m4BHnD3ewGiD8IKoLmX4gYadx9aEcFEH/K/unu7itieBO4+IPHczIYAl7j74fFFVLHcvXtFbCfVsamoc7uqqvEJIvJTd/9HiukdgJVJySExbWblhFWsqhBH4Rg6ALNKkxxEpBpz9xr9ABYCx6aYfiywEdgBrAeej/468D0wP1quDfD/gOXAl8AVSdvIAn4LzAfWAVOA9sD4pO2sBwam2H8d4PfAV8Ay4GlgD6BBqjhSrO9Al+j5aOBB4M0ojolA52ieAXdH+/gOmAEcGM37gPCLKLHNIcBH0fP50bHZmHR8tgJbov+PBUYQftEn1j8c+BhYAywChiTF96ek5U4GpkXLfQwcVOj9ujaK8zvgBaAh0KTQ+7UeaJPiuIwGHgLejpb5F/BD4B5gNTAH6JW0fE50HNYQkuEpSfNaAGOBtcB/gFsTxyeanw28B6wC5gI/KxTHn1K9d9H8S4HZ0fs1C+gdTR9Owfk0Czi90PvzL+D+6NjMAY5Jmn9h0jYXAL8otM9To+O+NtrHCcnnQXQsNhFK2+ujY3IIsBSom7SdM4FpRbyuPQjn8nLCuf17oE7y+UUoHa8mfJ4GFLGd4cBLhabdC9xX0msFjgLyU30HAI2i92Z1dHyvK7RsyuOf6tgUcW5fCsyLzomxJJ2jhM/sUOCLaP8PAlbE6x/Brp+tUwjn55ro/cpJmncD8E0U89zEOQH0ASZH7/dS4M+l/v6s6C/kqvagiASR6kRKehMTX7x1CF/6NwH1gf2ik/H4aP51wGfAAYQv4p5Ai8LbKWLfF0Un0n5AU+Bl4JlUcRSxfuEEsSo6IeoCzwJjonnHR69hzyjGHKB1NO8DikgQqY5dig/DzpMY2Dc6QQcB9QhfrrmF1wN6E5LVoYQEOzjaT4Okff6HkJh/QPgSGFrU+5XiuIwmVIMdTEgs/yR8EV0Q7e9PwPvRsvWi9+C30ft7dPQaDojmjwFeJCSnAwkfwkQCbUJIghdGx7x3tN/uqY5VoRjPjrZ1SPSedCFUcybmtSGcewMJPxJaJ70/24DfRLEPJCSKH0TzTwI6R9s8EthAQeLpEy37k2jbbYHswudB4XMgmjaLpC9y4BXgmiJe29PAa0AzoCPwX+DipG1vJXyJZgGXA4tJ8SVJKK1uIFRnEi2/BOibxmvd5Txh1wRxBzCBcG61Bz4vtGxJx7/wsdn5PhPOnxXRudCAkMjHF/rMvkH4LO5LSKInFHEcR1Dw2do/iuMn0ft+PeG8rU/47llElIiiY574cfgJcH70vGni2JXmUVsuUr9qZmuSHpemud4hQCt3v8Xdt7j7AuAx4Jxo/iXA7919rgfT3X1lmts+j5DRF7j7euBG4BwzK2u138vu/h9330ZIELnR9K2ED2s24YM4292XlHEfxTkP+Ie7P+/uW919pbtPS7HcpcBf3H2iu29396eAzUDfpGXuc/fF7r4KeD3ptaTrFXef4u6bCF9mm9z9aXffTiiRJC769yV8cO6I3t9/Ej7Ag8wsi/BL+SZ3/97dPweeStrHycBCdx/l7tvcfSqhpHlWGvFdAvyvu0+Kzpt57v4VgLv/LXrtO9z9BcKvzT5J6y4D7omO8QuEX4wnReu+6e7zo21+CPwdOCJa72LgSXd/L9r2N+4+J83j+RTwcwAz+wHhR8dzhReKjtlA4EZ3X+fuC4H/A85PWuwrd38sei+eAloTrhHuIjoeU4HToklHAxvc/d9pvNbi/Ay4zd1Xufsi4L5C+y3p+BfnPMIxnurumwmf6R+ZWcekZe5w9zXu/jXwPumd2wOBN6P3biuhBNYIOIxQomkAdDOzeu6+0N3nR+ttBbqYWUt3X584dqVRWxLEae6+Z9LjsTTX6wC0SU4uhF+biRO6PaE4WhZtCEXwhK8Iv0R3+7Ck6duk5xsIX3xEX3oPEIqzS83sUTNrXsZ9FCfdY9EBuKbQMW1POB4JKV9LKSxNer4xxf+J7bUBFrn7jqT5XxF+XbcivB+LCs1Lfh2HFnod5xGqs0pS5LEyswvMbFrSNg8EWiYt8o1HPwmTYmoTrTvAzP5tZquidU9MWrc85+pfgZ+aWVPCF+yEIn5ktCT8qi18XrdN+n/ne+vuG6KnRb2/zxFKpADnkpSUSnitxWlD0e9pOse/pG3v3F70w28lRbx+0j+3C293R/Qa2npoBHMVocSxzMzGmFnis3QxofQxx8wmmdnJab6OnWpLgiirRcCXhZJLM3c/MWl+5zJuezHhSyZhX0L1wdLUi5edu9/n7gcD3QknzHXRrO+BxkmLpvPlVpR0j8Uiwi+45GPa2N2fT2NdL3mRUlkMtDez5M/BvoTqn+WE96N9oXkJi4APC72Opu5+eRr7TXmszKwDoYQ6jFBVuSehCsSSFmtrZsn/7wssNrMGhBLMSGCfaN23ktZN9/3Z7Ri7+zeE6orTCaWBZ4pYdwXhV2vh8/qbNPabyt+Ao8ysXbTv5wDSeK3FWUIR72kax7+k82+Xz7SZNSFUtZb19Re1XSO8hm8A3P05Dy2rOkQx3hlN/8LdBwF7R9NeimJKmxJE8f4DrDWzG8yskZllmdmBZnZINP9x4FYz62rBQWbWIpq3lHB9oSjPA78xs07RL7PbgReiKqIKY2aHmNmhZlaPkBASF9ogXLA8w8wam1kXwi+OsnoWONbMfmZmdc2shZnlpljuMWBoFJOZWRMzO8nMmqWxj6VACzPboxxxJptIOCbXm1m9qBntTwnXb7YTrguNiI5PN8L1koQ3gP3N7Pxo3XrRsc5JY7+PA9ea2cHRMegSfTk1IXzAlwOY2YWEX7DJ9gauiPZ3NuGa0luEX+4NonW3mdkA4Lik9Z4ALjSzY8ysjpm1NbPsFLEtBdqZWf1C058m1H33IFTb7SY6Zi8Ct5lZs+g1XU0ogZSauy8nXB8ZRfihNjuaVdJrLc6LwI1mtleUeH6dNK+k41/UsUl4jnCMc6MkdjswMapqK48XgZOi964eoWn+ZuBjMzvAzI6O9reJUELeHsX/czNrFZU41kTb2r775otWWxLE6xZu9ko8Up7ghUUn/E8J9YRfEn4hPU5oqQHwZ8Kb93dCS4EnCHWDEIp8T0VF1Z+l2PyThF9i46Ntb2LXk7WiNCd8Ka8mFFNXEn55QWjdtIVw4j9F+JIvk6hO9UTCybuKkHx6plhuMuE6xANRTPMIF//S2cccQmJdEB3XNiWtU8L2thBahwwgvLcPARck1c0PI1QBfEu4GDkqad11hC+lcwi/8L4l/EprkMZ+/wbcRvhCWQe8SrjQPItQZ/8J4T3pQWi1lGwi0DWK9zbgLA/Xe9YBVxDOx9WEKpmxSfv8D+GC+t2Ei9Ufsusv/YR/ElrLfGtmK5KmvxIt/4q7f1/My/s1IekuILRYeo5wrpfVc4QWczurl0p6rSX4I+Fz8CXhc7uzNJTG8S/q2CTWHwf8gVC6WUIosZ1TeLnScve5hGtA9xPe958Smu5vIZxvd0TTvyX8gPhttOoJwEwzW09oAXaOh+tyabNdqzNFpKqymG9iM7P5hOakqe4pkhqotpQgRKQczOxMQvXLP+OORSpPbbmTWkTKyMw+ALoR2tTvKGFxqUFUxSQiIimpiklERFLKaBWTmZ1AuHqeBTzu7ncUmn8qoX+bHYQ251e5+0fRvD0JLYYOJNR9XuTunxS3v5YtW3rHjh0r+FWIiNRcU6ZMWeHurVLNy1gVk4Xb7v9L6D8kH5gEDIqakiWWaQp87+5uZgcBL7p7djTvKcIdm49H7Y4bu/ua4vaZl5fnkydPzsjrERGpicxsirvnpZqXySqmPsA8D30NbSF0fHZq8gJR/yCJDJW4SQULXUH0J9xXgId+ctZkMFYRESkkkwmiLbv2eZLPrn2SADtHTptD6Kr6omjyfoS7GUeZ2adm9nhRt4ib2WVmNtnMJi9fvrxiX4GISC2WyQSRql+UVP28vBJVK51GuB4BBd0nP+zuvQh3Zg5PtRN3f9Td89w9r1WrlNVoIiJSBpm8SJ3Prp1itSN0SZCSu483s85m1jJaN9/dJ0azX6KIBCEi8dm6dSv5+fls2lSqHhwkBg0bNqRdu3bUq1cv7XUymSAmAV3NrBOh18FzCH2m7BR1EDc/ukjdm9AJ18ro/0VmdkDUD8kxhEFLRKQKyc/Pp1mzZnTs2BGzdDpTlTi4OytXriQ/P59OnTqlvV7GEoS7bzOzYcC7hGauT7r7TDMbGs1/hDAgywVmtpXQC+HApIvWvwaejVowLSB0NCYiVcimTZuUHKoBM6NFixaU9jptRu+DcPe3CF0RJ097JOn5nUR9l6dYdxqQsumViFQdSg7VQ1neJ91JLSIiKSlBAOeeCzfdFHcUIlJaRx11FO++++4u0+655x5++ctfFrtO4obaE088kTVr1uy2zIgRIxg5cuRu05O9+uqrzJpVcGn0pptu4h//KH9P6B988AEnn1zq0UEzQgkC+OorGD8+7ihEpLQGDRrEmDFjdpk2ZswYBg0aVMQau3rrrbfYc889y7Tvwgnilltu4dhjjy3TtqoqJQggOxtmzy55ORGpWs466yzeeOMNNm/eDMDChQtZvHgxhx9+OJdffjl5eXl0796dm2++OeX6HTt2ZMWKMDjcbbfdxgEHHMCxxx7L3Llzdy7z2GOPccghh9CzZ0/OPPNMNmzYwMcff8zYsWO57rrryM3NZf78+QwZMoSXXnoJgHHjxtGrVy969OjBRRddtDO+jh07cvPNN9O7d2969OjBnDlzdg8qyapVqzjttNM46KCD6Nu3LzNmzADgww8/JDc3l9zcXHr16sW6detYsmQJ/fv3Jzc3lwMPPJAJEyaU7+CiBAFATg4sWwarVsUdiUj1dtRRuz8eeijM27Ah9fzRo8P8FSt2n1eSFi1a0KdPH9555x0glB4GDhyImXHbbbcxefJkZsyYwYcffrjzyzWVKVOmMGbMGD799FNefvllJk2atHPeGWecwaRJk5g+fTo5OTk88cQTHHbYYZxyyincddddTJs2jc6dO+9cftOmTQwZMoQXXniBzz77jG3btvHwww/vnN+yZUumTp3K5ZdfXmI11s0330yvXr2YMWMGt99+OxdccAEAI0eO5MEHH2TatGlMmDCBRo0a8dxzz3H88cczbdo0pk+fTm5ubskHsARKEIQEAVBCMheRKii5mim5eunFF1+kd+/e9OrVi5kzZ+5SHVTYhAkTOP3002ncuDHNmzfnlFNO2Tnv888/54gjjqBHjx48++yzzJw5s9h45s6dS6dOndh///0BGDx4MOOT6rDPOOMMAA4++GAWLlxY7LY++ugjzj//fACOPvpoVq5cyXfffUe/fv24+uqrue+++1izZg1169blkEMOYdSoUYwYMYLPPvuMZs2aFbvtdGhEOaB7dzjySNDYSSLl88EHRc9r3Lj4+S1bFj+/KKeddhpXX301U6dOZePGjfTu3Zsvv/ySkSNHMmnSJPbaay+GDBlS4t3eRTUDHTJkCK+++io9e/Zk9OjRfFBCkCX1kN2gQQMAsrKy2LZtW6m3ZWYMHz6ck046ibfeeou+ffvyj3/8g/79+zN+/HjefPNNzj//fK677rqdJY6yUgkC6NgxnJj9+sUdiYiUVtOmTTnqqKO46KKLdpYe1q5dS5MmTdhjjz1YunQpb7/9drHb6N+/P6+88gobN25k3bp1vP766zvnrVu3jtatW7N161aeffbZndObNWvGunXrdttWdnY2CxcuZN68eQA888wzHHnkkWV6bf3799+5zw8++ICWLVvSvHlz5s+fT48ePbjhhhvIy8tjzpw5fPXVV+y9995ceumlXHzxxUydOrVM+0ymEkQSd9A9PyLVz6BBgzjjjDN2VjX17NmTXr160b17d/bbbz/6lfDrr3fv3gwcOJDc3Fw6dOjAEUccsXPerbfeyqGHHkqHDh3o0aPHzqRwzjnncOmll3LfffftvDgNoc+jUaNGcfbZZ7Nt2zYOOeQQhg4dWqbXNWLECC688EIOOuggGjduzFNPPQWEprzvv/8+WVlZdOvWjQEDBjBmzBjuuusu6tWrR9OmTXn66afLtM9kNWpM6vIMGHTttfDOO/D55xUclEgNNnv2bHISF/Gkykv1fsU1YFC10qRJaOqqTilFRAIliEhODuzYAV98EXckIiJVgxJEJDs7/NUNcyKlU5OqqWuysrxPShCR/fcPF6iVIETS17BhQ1auXKkkUcUlxoNo2LBhqdZTK6ZI48bw61/DQQfFHYlI9dGuXTvy8/NLPc6AVL7EiHKloQSR5N57445ApHqpV69eqUYok+pFVUxJ3GHp0nCxWkSktlOCSDJ6NPzwh6H7bxGR2k4JIknXruGvOu0TEVGC2EXiBkO1ZBIRUYLYRYsWoUdJlSBERJQgdpOToxKEiAiometurroKSuiiXUSkVlCCKCQa7ElEpNZTFVMhW7bAlCnhfggRkdpMCaKQxYshLw/Gjo07EhGReClBFLLvvtCokS5Ui4goQRRSpw4ccICauoqIKEGkkJ2tEoSIiBJECjk5oT+mDRvijkREJD5q5prCoEHQrx/U1dERkVpMX4EpdO1a0HGfiEhtldEqJjM7wczmmtk8MxueYv6pZjbDzKaZ2WQzO7zQ/Cwz+9TM3shknKm88QZ89FFl71VEpOrIWIIwsyzgQWAA0A0YZGbdCi02Dujp7rnARcDjheZfCcRyufg3v4H77otjzyIiVUMmSxB9gHnuvsDdtwBjgFOTF3D39V4w2nkTYOfI52bWDjiJ3ZNGpcjOVlNXEandMpkg2gKLkv7Pj6btwsxON7M5wJuEUkTCPcD1QLEDgJrZZVH11OSKHDg9Jwf++1/Yvr3CNikiUq1kMkFYimm+2wT3V9w9GzgNuBXAzE4Glrn7lJJ24u6Punueu+e1atWqnCEXyM6GzZth4cIK26SISLWSyQSRD7RP+r8dsLiohd19PNDZzFoC/YBTzGwhoWrqaDP7awZj3Y1GlxOR2i6TCWIS0NXMOplZfeAcYJcu8Mysi5lZ9Lw3UB9Y6e43uns7d+8YrfdPd/95BmPdTa9e4RrE8cdX5l5FRKqOjN0H4e7bzGwY8C6QBTzp7jPNbGg0/xHgTOACM9sKbAQGJl20jlXDhqFPJhGR2sqqyPdxhcjLy/PJkydX2PZeew3mzYNrrqmwTYqIVClmNsXd81LNU19MxXjnHbjtNqhBOVREJG1KEMXIyYHVq2HZsrgjERGpfEoQxcjODn/VkklEaiMliGIkmrrqjmoRqY2UIIrRrh00bQrffBN3JCIilU/dfRfDLFx/aNQo7khERCqfShAlUHIQkdpKCaIE778Pp58O69fHHYmISOVSgijB6tXw6qswd27ckYiIVC4liBIkmrqqJZOI1DZKECXo0gWysnQvhIjUPkoQJahfHzp3VglCRGofNXNNQ9++GllORGofJYg0PPVU3BGIiFQ+VTGJiEhKShBpWLAA8vLg7bfjjkREpPIoQaShRQuYMgWmT487EhGRyqMEkYY99oA2bdSSSURqFyWINGVn614IEaldlCDSlJMTShAaflREags1c03TEUfA0qWwcSM0bhx3NCIimacEkaaBA8NDRKS2UBVTKemOahGpLZQgSuGAA+Cqq+KOQkSkcihBlMKee6olk4jUHkoQpZCdrXshRKT2UIIohZwc+OYbWLs27khERDJPCaIUEqPLafhREakNlCBKoXfvcJF6jz3ijkREJPN0H0Qp7Lsv3H133FGIiFQOlSBKafNm+PrruKMQEck8JYhSOvdcOO64uKMQEcm8jCYIMzvBzOaa2TwzG55i/qlmNsPMppnZZDM7PJre3szeN7PZZjbTzK7MZJylkZ0N8+bBli1xRyIiklkZSxBmlgU8CAwAugGDzKxbocXGAT3dPRe4CHg8mr4NuMbdc4C+wK9SrBuLnJzQ3cb8+XFHIiKSWZksQfQB5rn7AnffAowBTk1ewN3Xu+/sQLsJ4NH0Je4+NXq+DpgNtM1grGlLNHXVHdUiUtNlMkG0BRYl/Z9Pii95MzvdzOYAbxJKEYXndwR6ARNT7cTMLouqpyYvX768IuIuViJB6I5qEanpMpkgLMW03YbbcfdX3D0bOA24dZcNmDUF/h9wlbunvH/Z3R919zx3z2vVqlX5oy5B06bw0EMwYEDGdyUiEqtM3geRD7RP+r8dsLiohd19vJl1NrOW7r7CzOoRksOz7v5yBuMstcsvjzsCEZHMy2QJYhLQ1cw6mVl94BxgbPICZtbFzCx63huoD6yMpj0BzHb3P2cwxjJZvhzeeUfDj4pIzZaxBOHu24BhwLuEi8wvuvtMMxtqZkOjxc4EPjezaYQWTwOji9b9gPOBo6MmsNPM7MRMxVpaL70Uqpjy8+OOREQkczLa1Ya7vwW8VWjaI0nP7wTuTLHeR6S+hlEl5OSEv3PmQPv2xS8rIlJd6U7qMlBTVxGpDZQgymCffTS6nIjUfEoQZWCm0eVEpOZTd99ldO+94Z4IEZGaSgmijPr0iTsCEZHMUhVTGa1aBU88AV9+GXckIiKZoQRRRitXwiWXwAcfxB2JiEhmKEGUUadOUL++WjKJSM2lBFFGdevC/vurJZOI1FxKEOWQna0ShIjUXGklCDNrYmZ1ouf7m9kpUW+rtVpODixYAJs3xx2JiEjFS7cEMR5oaGZtCcOEXgiMzlRQ1cUVV8CyZdCgQdyRiIhUvHQThLn7BuAM4H53P50wznSt1rIltGgRdxQiIpmRdoIwsx8B5xGGBgXdZIc73HILvFylhjMSEakY6SaIq4AbgVeiMR32A97PWFTVhBk8+WQYH0JEpKZJqxTg7h8CHwJEF6tXuPsVmQysusjJUVNXEamZ0m3F9JyZNTezJsAsYK6ZXZfZ0KqHRK+uO3bEHYmISMVKt4qpm7uvBU4jjBC3L2FI0FovJwc2boSvv447EhGRipVugqgX3fdwGvCau28FPGNRVSPZ2dCokcanFpGaJ92WSH8BFgLTgfFm1gFYm6mgqpN+/WD9eqije9JFpIZJ62vN3e9z97bufqIHXwE/znBs1UJWVkgO27fHHYmISMVK9yL1Hmb2ZzObHD3+D2iS4diqjU8/hS5dYMqUuCMREak46VaMPAmsA34WPdYCozIVVHXTuTOsXg3/8z9xRyIiUnHSTRCd3f1md18QPf4I7JfJwKqT5s1h2LBwR7XuiRCRmiLdBLHRzA5P/GNm/YCNmQmperrySmjYEO68M+5IREQqRroJYijwoJktNLOFwAPALzIWVTXUqhVcein89a+waFHc0YiIlF+6XW1MB3qaWfPo/7VmdhUwI4OxVTvXXQdHHw1t28YdiYhI+ZWqR9bobuqEq4F7KjSaaq5du/AQEakJynN7l1VYFDWIO9x0k65FiEj1V54Eoa42UjAL41T/z//Ad9/FHY2ISNkVmyDMbJ2ZrU3xWAe0qaQYq50bbwzJ4eGH445ERKTsik0Q7t7M3ZuneDRz91o/olxReveG44+Hu+8OPb2KiFRHGe1izsxOMLO5ZjbPzIanmH+qmc0ws2lRFx6Hp7tuVXfjjbBsWRhxTkSkOspYgjCzLOBBYADQDRhkZt0KLTYO6OnuucBFwOOlWLdK698fhg+HH/0o7khERMomk9VEfYB57r4AwMzGAKcSRqQDwN3XJy3fhIIL3yWuW9WZqW8mEaneMlnF1BZIvqc4P5q2CzM73czmAG8SShFpr1sdzJsHv/2thiQVkeonkwki1X0SuzWNdfdX3D2bMFrdraVZF8DMLkt0Q758+fKyxpoxkyaFksRrr8UdiYhI6WQyQeQD7ZP+bwcsLmphdx8PdDazlqVZ190fdfc8d89r1apV+aOuYGefHboDv/32cBOdiEh1kckEMQnoamadzKw+cA4wNnkBM+tiZhY97w3UB1ams251UbcuXH89TJ4M48bFHY2ISPoyliDcfRswDHgXmA286O4zzWyomQ2NFjsT+NzMphFaLQ2MhjRNuW6mYs20wYOhdetQihARqS7Ma1C9R15enk+ePDnuMFJ64AGYNQvuvRfq1Ys7GhGRwMymuHteqnm6G7qSDBsWdwQiIqWT0TupZXcTJsAXX8QdhYhIyZQgKtF338GAAXDLLXFHIiJSMiWISrTHHvCLX8Dzz8OXX8YdjYhI8ZQgKtnVV0OdOnDXXXFHIiJSPCWISta2LQwZEnp5/fbbuKMRESmaEkQMrr8e9twTZlbbOztEpDZQM9cYdOkCixbpfggRqdpUgohJvXqwfTvMmRN3JCIiqSlBxOiXv4TDD4fvv487EhGR3SlBxGjwYFi5Eh5/PO5IRER2pwQRo8MOC0OTjhwJW7bEHY2IyK6UIGJ2442Qnw+jR8cdiYjIrpQgYnb88aEk8eKLGlBIRKoWNXONmRm8/DLstVd4LiJSVagEUQXssw/Urw+rV4d+mkREqgIliCrkzjvh3HPhvffijkRERAmiSrnpJujWDc4/H5YujTsaEantlCCqkMaNYcyYMG7E4MGwY0fcEYlIbaYEUcX06AF33w3vvgv33x93NCJSm6kVUxX0i1+EO6zPPjvuSESkNlOCqILM4He/C8+3b4fNm0P1k4hIZVIVUxW2YweceCJcfLFuohORyqcEUYXVqQNHHhkuXI8aFXc0IlLbKEFUcTfcAMccA8OGwezZcUcjIrWJEkQVl5UFzzwDTZvCOefAxo1xRyQitYUSRDXQujU89RSsXRuGKhURqQxqxVRNDBgQhidt0CDuSESktlAJohpp0CA0eb3xRvj667ijEZGaTgmimlm8GB58MHTqt21b3NGISE2mBFHNdOoEjzwC//oX/PGPcUcjIjWZEkQ1dO65MGQI3HYbvP9+3NGISE2lBFFN3X8/7L8/XHqpqppEJDMymiDM7AQzm2tm88xseIr555nZjOjxsZn1TJr3GzObaWafm9nzZtYwk7FWN02bwt/+Bq+9BnXVFk1EMiBjCcLMsoAHgQFAN2CQmXUrtNiXwJHufhBwK/BotG5b4Aogz90PBLKAczIVa3XVowd07x76abr/fli1Ku6IRKQmyWQJog8wz90XuPsWYAxwavIC7v6xu6+O/v030C5pdl2gkZnVBRoDizMYa7U2fTpceSXstx/cfjt8/33cEYlITZDJBNEWSL7vNz+aVpSLgbcB3P0bYCTwNbAE+M7d/55qJTO7zMwmm9nk5cuXV0jg1U1uLsyYAf37h27Cu3QJLZ22bo07MhGpzjKZICzFtJSdVpvZjwkJ4obo/70IpY1OQBugiZn9PNW67v6ou+e5e16rVq0qJPDq6MADYexYmDABOneGP/1JF69FpHwymSDygfZJ/7cjRTWRmR0EPA6c6u4ro8nHAl+6+3J33wq8DByWwVhrjMMPD0li4kRo1Ai2bIEzz4T33os7MhGpbjKZICYBXc2sk5nVJ1xkHpu8gJntS/jyP9/d/5s062ugr5k1NjMDjgHU2XWazKBtVJm3YAFMmQLHHQfHHguTJ8cbm4hUHxlLEO6+DRgGvEv4cn/R3Wea2VAzGxotdhPQAnjIzKaZ2eRo3YnAS8BU4LMozkczFWtNlp0Nc+fCPfeEi9mHHBLGul67Nu7IRKSqM69BY1nm5eX5ZP1ELtLatfDnP8OHH8K4cWHEus2b1UOsSG1mZlPcPS/VPN1JXYs0bw4jRsA//xmSw8qV0LEjDB8enouIJFOCqIUsal+2dWu4LvG//xuuWfz85+ECdw0qVIpIOShB1GI//GEYzvSzz+CSS+D118O9FPPmhflKFCK1mxKE0L07PPBAGGvi9deha9cwffDgUKoYP17JQqQ2UoKQnZo0gZNPDs/doWVLeOMNOPJI6NYN7r5b1ypEahMlCEnJLLR4WrwYRo2CvfaCq68OzWUBduxQqUKkplOCkGI1bhwGJ/r449Df069+Faa/8Qbk5IQkolKFSM2kBCFp69EjXNiGUB31gx/ANddAmzZw8cXhrm0RqTmUIKRMjjmmoFRxySXw7LPwk5+EqicRqRmUIKRcevSABx8MpYenny64O/s3v1GJQqS6U4KQCtGmDfTrF55PmgQPPxzGzFbVk0j1pQQhFe7ww0NS+NWvQtVTIlFs2BB3ZCJSGkoQkhFt2sC99xYkii++CONTAKxbF29sIpIeJQjJqESi+OCDcG/FihWw776qehKpDpQgpFLUic40s9CFR3LVkxKFSNWkBCGVqkWLcDf2ggUwbFhIFNnZBdcnFi6E776rvHi2b6+8fYlUN0oQEos2bQoSxW23hTu2AX75y9Ctx4EHwqWXwhNPwJw5FbPPdetCx4MPPBC23acPNGsGS5eG+TNmhK5FRCTQiHJSpYwfH65X/Pvf4bF6deiC/MMPw/xHHoEOHeDQQ8Od3Kns2AHz54chVqdPD1VaXbrA6NFw4YVhmZYtoWfP8Lj2WmjdGg47DKZODdVeN9wQrpWI1HTFjSinBCFV1o4dofXT+vVw8MGwZQvssQds2hTmH3AA9O0L554Lxx0Hs2fDRReF8S2+/z4sU6cOvPginHkmLFkC06aFpNC6dcHASQkLFsAdd4RE4h4Sy403QufOlfmqRSpXcQmibmUHI5KuOnVCEkioXx+WLYPJk0Pp4pNP4M03w3gWxx0XShQNGoQkkSgddO9e0Ly2devwKMp++8Gjj8Lvfw933QWPPRYS0+WXZ/Z1ilRVKkFIteYehk6tX7/it71kSbge0rAh/OUvMG4c/O53IfGI1BTFlSB0kVqqNbPMJAcIpY2GDcPzTZvgnXcgNxdOPTV0JyJS0ylBiKThyivhq6/gj3+ECRNCC6hrrok7KpHMUoIQSdNee8FNN4V7Ne64I1z3gHB3+BNPhNZXX32leyuk5tBFapFSat48NINN+MtfwoXthLp1QxPZ994LF74//TS0sOrYETp1CoMuFW5BJVIVKUGIlNMNN8DAgaFk8eWXBY+WLcP8F18MJY6Ehg3DvRxTpoSR+T76CL75Btq3h3btwrWPevVieSnV0urV4e77Dh2UeCuaEoRIOdWtG27E69Il9fw//AEuuGDX5LFkScHd4488ErocSahTJ2xr7tzw/zPPwLffFiSQdu3CneiZujhfXYwbF0pvr70W7pHZe2847bQwDUJVX1ZWrCFWe0oQIhnWuDHk5IRHKg89BMOHQ35+wWPr1oL5zz0XWlAly8mBWbPC89//PvyK/uEPCx6dOoXuSmqa2bPDvTF16oTE8P774T6Vrl3hP/8pSLoQ+vjac0/40Y8KHipllI7ugxCpBtau3TWB1KsH558f5p14IkycCKtWFSx/3HHw7rvhee/esHHjrgmkXz8466ww//PPw/Y2bQqPzZvDMvvvHxLVmDEF0xPL9OsHP/4xrFkD118fvoj79AldoLRrV7FfwqtWwfPPhzvcJ08O3a707x+SYpMmqUtS27aFBgWffBISR6IzyGuugZEjQ+nik0/CjZCJGylrK91JLVLNNW8O3bqFR2FvvRX+bt4c7jRfujRUeyUcfXRoXfXtt+ELdunSkHDOOivcaNi7964lFoArrgjjeGzbFqrHCvvtb0OC2L4dXn89fIlv2RLmtW4dOmL82c9CTJs3h/hLa+nS0OPv2LFh27m5cPfdBcdgr72KXrduXbj99vB827bQ/conn8BBB4Vps2bBEUeExJibG25+3Gef0G1Lt24FCXnvvcMd+nVqaXtPJQiRGqJBg3Cdon37XaePHLn7stu2hb87doRf55s3h1/SDRqEi+iJjgobNgz9YTVsWPBo0KAgAbVoEa6nbN4cOkacODH8Ym/XLsx///1QwsnJKShhHHoo9OixaxJL+Pzz0KPucceFBDBrVujhd/Dg8EVeFnXrQq9e4ZHQsWOoovr445A4Xn89NFfu2zckiPHj4ac/DctmZYUGB/vsE5oz5+WFnn/feitM23vvUJLZuDGUbJo0CcdiwoQwbePGUOrauBFuuSX0IDxmTDjuifmNG4fk9Yc/lC2ZZoqqmEQkY774InwZTpwYHitWhOmJThMnTw49765YAaNGhZZdXbuGC/RmoYRTWdcMduwI+8vKCklqwoSCElni7113haq3xx6Dyy7bfRuzZoVkePfdcPXVBdPr1g0JePZsaNsWHn44XExv1Cgk3e++C51FLl8eSjXXXhsuwidKN4lHUT0Yl0dsvbma2QnAvUAW8Li731Fo/nlAokX5euByd58ezdsTeBw4EHDgInf/pLj9KUGIVF3uoSnwxImheqtu3VCVdf/9YX5uLgwZEqp5WrWKMdA0bdgQEseyZaH34EaNQimgcePQA/HGjQUJIFVpqbDkVld/+Qu88kooiXz7bZjWrh0sWhSeP/dc2GbPnqHFW3laa8WSIMwsC/gv8BMgH5gEDHL3WUnLHAbMdvfVZjYAGOHuh0bzngImuPvjZlYfaOzua4rbpxKESPWydWu4PtCgQeh5V3a3bFlIFGvXhm7rIbTQSjSDbtwY/vWvslfBxXWRug8wz90XREGMAU4FdiYId/84afl/A+2iZZsD/YEh0XJbgC0ZjFVEYlCvXrhILkXbe2/4yU92nTZ9eqjOSgyKtd9+mdl3JhNEW2BR0v/5wKHFLH8x8Hb0fD9gOTDKzHoCU4Ar3f37wiuZ2WXAZQD7aggwEakFGjTY/cJ7JmSy8VaqS0sp67PM7MeEBJG4HlEX6A087O69gO+B4anWdfdH3T3P3fNaVYeKSxGRaiKTCSIfSG5w1w7YbUh4MzuIcDH6VHdfmbRuvrtPjP5/iZAwRESkkmQyQUwCuppZp+gi8znA2OQFzGxf4GXgfHf/b2K6u38LLDKzxICTx5B07UJERDIvY9cg3H2bmQ0D3iU0c33S3Wea2dBo/iPATUAL4CELjZ23JV1N/zXwbJRcFgAXZipWERHZnW6UExGpxTQmtYiIlJoShIiIpKQEISIiKdWoaxBmthz4Ku44itASWBF3EMVQfOWj+MpH8ZVPeeLr4O4pbyKrUQmiKjOzyUVdCKoKFF/5KL7yUXzlk6n4VMUkIiIpKUGIiEhKShCV59G4AyiB4isfxVc+iq98MhKfrkGIiEhKKkGIiEhKShAiIpKSEkQFMrP2Zva+mc02s5lmdmWKZY4ys+/MbFr0uKmSY1xoZp9F+96t4yoL7jOzeWY2w8wqrZt1Mzsg6bhMM7O1ZnZVoWUq9fiZ2ZNmtszMPk+a9gMze8/Mvoj+7lXEuieY2dzoWKYczyRD8d1lZnOi9++VaHz3VOsWey5kML4RZvZN0nt4YhHrxnX8XkiKbaGZTSti3co4fim/UyrtHHR3PSroAbQGekfPmxHG5O5WaJmjgDdijHEh0LKY+ScSRvYzoC8wMaY4s4BvCTfxxHb8CEPf9gY+T5r2v8Dw6Plw4M4i4p9PGB2xPjC98LmQwfiOA+pGz+9MFV8650IG4xsBXJvG+x/L8Ss0//+Am2I8fim/UyrrHFQJogK5+xJ3nxo9XwfMJgy9Wp2cCjztwb+BPc2sdQxxHAPMd/dY74x39/HAqkKTTwWeip4/BZyWYtWdY7J7GFM9MSZ7xuNz97+7+7bo351jvcehiOOXjtiOX4KFMQh+Bjxf0ftNVzHfKZVyDipBZIiZdQR6ARNTzP6RmU03s7fNrHvlRoYDfzezKdF43oWlGks8jiR3DkV/MOM8fgD7uPsSCB9gYO8Uy1SV43gRBWO9F1bSuZBJw6IqsCeLqB6pCsfvCGCpu39RxPxKPX6FvlMq5RxUgsgAM2sK/D/gKndfW2j2VEK1SU/gfuDVSg6vn7v3BgYAvzKz/oXmpz2WeKZYGCTqFOBvKWbHffzSVRWO4++AbcCzRSxS0rmQKQ8DnYFcYAmhGqew2I8fMIjiSw+VdvxK+E4pcrUU00p1DJUgKpiZ1SO8kc+6+8uF57v7WndfHz1/C6hnZi0rKz53Xxz9XQa8QiiGJktrLPEMGwBMdfelhWfEffwiSxPVbtHfZSmWifU4mtlg4GTgPI8qpAtL41zICHdf6u7b3X0H8FgR+437+NUFzgBeKGqZyjp+RXynVMo5qARRgaI6yyeA2e7+5yKW+WG0HGbWh/AerKyk+JqYWbPEc8LFzM8LLTYWuMCCvsB3iaJsJSryl1ucxy/JWGBw9Hww8FqKZUockz1TzOwE4AbgFHffUMQy6ZwLmYov+ZrW6UXsN7bjFzkWmOPu+almVtbxK+Y7pXLOwUxega9tD+BwQhFuBjAtepwIDAWGRssMA2YSWhT8GzisEuPbL9rv9CiG30XTk+Mz4EFC64fPgLxKPoaNCV/4eyRNi+34ERLVEmAr4RfZxYRx1McBX0R/fxAt2wZ4K2ndEwmtTuYnjnUlxTePUPecOAcfKRxfUedCJcX3THRuzSB8YbWuSscvmj46cc4lLRvH8SvqO6VSzkF1tSEiIimpiklERFJSghARkZSUIEREJCUlCBERSUkJQkREUlKCECmBmW23XXuZrbCeRc2sY3JPoiJVSd24AxCpBja6e27cQYhUNpUgRMooGg/gTjP7T/ToEk3vYGbjos7oxpnZvtH0fSyMzzA9ehwWbSrLzB6L+vv/u5k1ipa/wsxmRdsZE9PLlFpMCUKkZI0KVTENTJq31t37AA8A90TTHiB0mX4QoaO8+6Lp9wEfeuhosDfhDlyArsCD7t4dWAOcGU0fDvSKtjM0My9NpGi6k1qkBGa23t2bppi+EDja3RdEHap96+4tzGwFofuIrdH0Je7e0syWA+3cfXPSNjoC77l71+j/G4B67v4nM3sHWE/osfZVjzopFKksKkGIlI8X8byoZVLZnPR8OwXXBk8i9It1MDAl6mFUpNIoQYiUz8Ckv59Ezz8m9JwJcB7wUfR8HHA5gJllmVnzojZqZnWA9u7+PnA9sCewWylGJJP0i0SkZI1s14Hr33H3RFPXBmY2kfBja1A07QrgSTO7DlgOXBhNvxJ41MwuJpQULif0JJpKFvBXM9uD0MPu3e6+poJej0hadA1CpIyiaxB57r4i7lhEMkFVTCIikpJKECIikpJKECIikpIShIiIpKQEISIiKSlBiIhISkoQIiKS0v8Hcf4bOy43Ys8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.3684 - accuracy: 0.8954 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9499 - val_loss: 0.1483 - val_accuracy: 0.9571\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1201 - accuracy: 0.9631 - val_loss: 0.1235 - val_accuracy: 0.9636\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9725 - val_loss: 0.1049 - val_accuracy: 0.9691\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.9780 - val_loss: 0.1105 - val_accuracy: 0.9669\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9822 - val_loss: 0.1035 - val_accuracy: 0.9705\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9856 - val_loss: 0.0950 - val_accuracy: 0.9732\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0411 - accuracy: 0.9875 - val_loss: 0.0965 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.1056 - val_accuracy: 0.9712\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.0927 - val_accuracy: 0.9759\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0254 - accuracy: 0.9918 - val_loss: 0.1086 - val_accuracy: 0.9734\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.1141 - val_accuracy: 0.9721\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.1098 - val_accuracy: 0.9732\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.1130 - val_accuracy: 0.9764\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.1209 - val_accuracy: 0.9760\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.1167 - val_accuracy: 0.9757\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1261 - val_accuracy: 0.9748\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1229 - val_accuracy: 0.9765\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1260 - val_accuracy: 0.9770\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1332 - val_accuracy: 0.9773\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Dataset curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Regularizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Reducing the network's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 31ms/step - loss: 0.5531 - accuracy: 0.7779 - val_loss: 0.4318 - val_accuracy: 0.8674\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3534 - accuracy: 0.8953 - val_loss: 0.3336 - val_accuracy: 0.8832\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2560 - accuracy: 0.9185 - val_loss: 0.2953 - val_accuracy: 0.8871\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2014 - accuracy: 0.9361 - val_loss: 0.2890 - val_accuracy: 0.8831\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1601 - accuracy: 0.9465 - val_loss: 0.2797 - val_accuracy: 0.8879\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1323 - accuracy: 0.9579 - val_loss: 0.2868 - val_accuracy: 0.8880\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1069 - accuracy: 0.9695 - val_loss: 0.2984 - val_accuracy: 0.8876\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0885 - accuracy: 0.9761 - val_loss: 0.3352 - val_accuracy: 0.8808\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0746 - accuracy: 0.9806 - val_loss: 0.3389 - val_accuracy: 0.8824\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0627 - accuracy: 0.9833 - val_loss: 0.3631 - val_accuracy: 0.8780\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0491 - accuracy: 0.9886 - val_loss: 0.4184 - val_accuracy: 0.8720\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0416 - accuracy: 0.9907 - val_loss: 0.4173 - val_accuracy: 0.8775\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0349 - accuracy: 0.9924 - val_loss: 0.4391 - val_accuracy: 0.8767\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0256 - accuracy: 0.9953 - val_loss: 0.4816 - val_accuracy: 0.8726\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0202 - accuracy: 0.9961 - val_loss: 0.5210 - val_accuracy: 0.8706\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9977 - val_loss: 0.6015 - val_accuracy: 0.8598\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.5882 - val_accuracy: 0.8727\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 0.6407 - val_accuracy: 0.8686\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.6737 - val_accuracy: 0.8680\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.7201 - val_accuracy: 0.8664\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with lower capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 27ms/step - loss: 0.6145 - accuracy: 0.6305 - val_loss: 0.5455 - val_accuracy: 0.7407\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5096 - accuracy: 0.8045 - val_loss: 0.5014 - val_accuracy: 0.8293\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.4629 - accuracy: 0.8697 - val_loss: 0.4823 - val_accuracy: 0.8309\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.4304 - accuracy: 0.9017 - val_loss: 0.4869 - val_accuracy: 0.8158\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4064 - accuracy: 0.9197 - val_loss: 0.4600 - val_accuracy: 0.8620\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3861 - accuracy: 0.9349 - val_loss: 0.4559 - val_accuracy: 0.8673\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.3684 - accuracy: 0.9467 - val_loss: 0.4681 - val_accuracy: 0.8544\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3538 - accuracy: 0.9539 - val_loss: 0.4495 - val_accuracy: 0.8722\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3392 - accuracy: 0.9628 - val_loss: 0.4689 - val_accuracy: 0.8631\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3269 - accuracy: 0.9679 - val_loss: 0.4643 - val_accuracy: 0.8672\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.3150 - accuracy: 0.9713 - val_loss: 0.5545 - val_accuracy: 0.8287\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.3046 - accuracy: 0.9737 - val_loss: 0.4581 - val_accuracy: 0.8726\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2944 - accuracy: 0.9780 - val_loss: 0.4968 - val_accuracy: 0.8606\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2855 - accuracy: 0.9799 - val_loss: 0.4980 - val_accuracy: 0.8622\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2762 - accuracy: 0.9833 - val_loss: 0.5058 - val_accuracy: 0.8616\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2682 - accuracy: 0.9844 - val_loss: 0.5465 - val_accuracy: 0.8548\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2608 - accuracy: 0.9846 - val_loss: 0.5673 - val_accuracy: 0.8539\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2533 - accuracy: 0.9853 - val_loss: 0.5732 - val_accuracy: 0.8553\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2462 - accuracy: 0.9869 - val_loss: 0.5398 - val_accuracy: 0.8627\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2395 - accuracy: 0.9870 - val_loss: 0.5976 - val_accuracy: 0.8544\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with higher capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 33ms/step - loss: 0.5463 - accuracy: 0.7666 - val_loss: 0.3772 - val_accuracy: 0.8440\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2564 - accuracy: 0.8989 - val_loss: 0.2655 - val_accuracy: 0.8944\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1545 - accuracy: 0.9405 - val_loss: 0.3117 - val_accuracy: 0.8808\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1051 - accuracy: 0.9683 - val_loss: 0.3648 - val_accuracy: 0.8860\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1137 - accuracy: 0.9754 - val_loss: 0.3545 - val_accuracy: 0.8717\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 0.4905 - val_accuracy: 0.8871\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.6393 - val_accuracy: 0.8801\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.8748e-04 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.8845\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.1283e-05 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.8843\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 6.2810e-06 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.8860\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5783e-06 - accuracy: 1.0000 - val_loss: 1.0364 - val_accuracy: 0.8851\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 4.4917e-07 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.8849\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.4615e-07 - accuracy: 1.0000 - val_loss: 1.1772 - val_accuracy: 0.8845\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 5.9516e-08 - accuracy: 1.0000 - val_loss: 1.2248 - val_accuracy: 0.8849\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 3.1723e-08 - accuracy: 1.0000 - val_loss: 1.2660 - val_accuracy: 0.8852\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 2.0436e-08 - accuracy: 1.0000 - val_loss: 1.2908 - val_accuracy: 0.8850\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.5075e-08 - accuracy: 1.0000 - val_loss: 1.3091 - val_accuracy: 0.8849\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 1.1963e-08 - accuracy: 1.0000 - val_loss: 1.3251 - val_accuracy: 0.8848\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 9.8739e-09 - accuracy: 1.0000 - val_loss: 1.3364 - val_accuracy: 0.8850\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 8.4113e-09 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding weight regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding L2 weight regularization to the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5841 - accuracy: 0.7906 - val_loss: 0.4656 - val_accuracy: 0.8609\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.3909 - accuracy: 0.8963 - val_loss: 0.3844 - val_accuracy: 0.8833\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3225 - accuracy: 0.9155 - val_loss: 0.3602 - val_accuracy: 0.8883\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2878 - accuracy: 0.9282 - val_loss: 0.3553 - val_accuracy: 0.8884\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2681 - accuracy: 0.9342 - val_loss: 0.3564 - val_accuracy: 0.8848\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2499 - accuracy: 0.9417 - val_loss: 0.3532 - val_accuracy: 0.8881\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2456 - accuracy: 0.9426 - val_loss: 0.3597 - val_accuracy: 0.8820\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2328 - accuracy: 0.9471 - val_loss: 0.3894 - val_accuracy: 0.8747\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2270 - accuracy: 0.9488 - val_loss: 0.3694 - val_accuracy: 0.8822\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2211 - accuracy: 0.9521 - val_loss: 0.3868 - val_accuracy: 0.8779\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2145 - accuracy: 0.9547 - val_loss: 0.3881 - val_accuracy: 0.8785\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2089 - accuracy: 0.9567 - val_loss: 0.4417 - val_accuracy: 0.8591\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2185 - accuracy: 0.9503 - val_loss: 0.3909 - val_accuracy: 0.8770\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2032 - accuracy: 0.9604 - val_loss: 0.3905 - val_accuracy: 0.8774\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1984 - accuracy: 0.9617 - val_loss: 0.4097 - val_accuracy: 0.8741\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2014 - accuracy: 0.9582 - val_loss: 0.4002 - val_accuracy: 0.8772\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1969 - accuracy: 0.9617 - val_loss: 0.4459 - val_accuracy: 0.8649\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1973 - accuracy: 0.9602 - val_loss: 0.4193 - val_accuracy: 0.8725\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1877 - accuracy: 0.9641 - val_loss: 0.4103 - val_accuracy: 0.8766\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1961 - accuracy: 0.9597 - val_loss: 0.4262 - val_accuracy: 0.8709\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Different weight regularizers available in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x1a7990519d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding dropout to the IMDB model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.6360 - accuracy: 0.6267 - val_loss: 0.5209 - val_accuracy: 0.8382\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5268 - accuracy: 0.7544 - val_loss: 0.4320 - val_accuracy: 0.8632\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.4459 - accuracy: 0.8223 - val_loss: 0.3806 - val_accuracy: 0.8757\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.3876 - accuracy: 0.8611 - val_loss: 0.3408 - val_accuracy: 0.8778\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.3418 - accuracy: 0.8867 - val_loss: 0.3082 - val_accuracy: 0.8843\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3055 - accuracy: 0.8998 - val_loss: 0.2873 - val_accuracy: 0.8916\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2664 - accuracy: 0.9180 - val_loss: 0.2800 - val_accuracy: 0.8902\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2404 - accuracy: 0.9267 - val_loss: 0.2865 - val_accuracy: 0.8906\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2118 - accuracy: 0.9347 - val_loss: 0.2899 - val_accuracy: 0.8848\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1894 - accuracy: 0.9423 - val_loss: 0.2987 - val_accuracy: 0.8900\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.1718 - accuracy: 0.9475 - val_loss: 0.3148 - val_accuracy: 0.8855\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1553 - accuracy: 0.9527 - val_loss: 0.3327 - val_accuracy: 0.8874\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1430 - accuracy: 0.9555 - val_loss: 0.3558 - val_accuracy: 0.8873\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1352 - accuracy: 0.9581 - val_loss: 0.4023 - val_accuracy: 0.8880\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.1246 - accuracy: 0.9608 - val_loss: 0.4105 - val_accuracy: 0.8867\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1106 - accuracy: 0.9662 - val_loss: 0.4390 - val_accuracy: 0.8866\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.1080 - accuracy: 0.9669 - val_loss: 0.4548 - val_accuracy: 0.8855\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.0998 - accuracy: 0.9706 - val_loss: 0.5185 - val_accuracy: 0.8858\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0978 - accuracy: 0.9704 - val_loss: 0.4976 - val_accuracy: 0.8855\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0967 - accuracy: 0.9717 - val_loss: 0.5311 - val_accuracy: 0.8848\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "71a77cf6d3857461ac3c38ebff3fad34580257a95b1e5ea33ee9699e2f5f6585"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
